{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import GAT, GCN\n",
    "from utils import TSP\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import SGD, Adam\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "BATCH_SIZE = 100\n",
    "EPOCH = 1000\n",
    "TEST = 100\n",
    "LR = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = TSP(20, 'train_tsp20')\n",
    "validset = TSP(20, 'valid_tsp20')\n",
    "\n",
    "trainloader = DataLoader(trainset, BATCH_SIZE, shuffle=True, num_workers=6)\n",
    "validloader = DataLoader(validset, BATCH_SIZE, shuffle=True, num_workers=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GCN(trainset[0][2].shape[1], 1024, trainset[0][0].shape[0], 0.3, True).cuda()\n",
    "# model = GAT(trainset[0][1].shape[1], 16, trainset[0][0].shape[0], 0.3, True).cuda()\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optim = Adam(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1/1000]  loss: 3.0008   precision: 4.20%\n",
      "[  2/1000]  loss: 2.9959   precision: 5.45%\n",
      "[  3/1000]  loss: 2.9971   precision: 5.35%\n",
      "[  4/1000]  loss: 2.9978   precision: 4.50%\n",
      "[  5/1000]  loss: 2.9959   precision: 5.25%\n",
      "[  6/1000]  loss: 2.9962   precision: 5.05%\n",
      "[  7/1000]  loss: 2.9978   precision: 5.05%\n",
      "[  8/1000]  loss: 2.9951   precision: 4.85%\n",
      "[  9/1000]  loss: 2.9955   precision: 4.90%\n",
      "[ 10/1000]  loss: 2.9943   precision: 4.60%\n",
      "[ 11/1000]  loss: 2.9948   precision: 5.30%\n",
      "[ 12/1000]  loss: 2.9972   precision: 5.05%\n",
      "[ 13/1000]  loss: 2.9961   precision: 5.50%\n",
      "[ 14/1000]  loss: 2.9964   precision: 4.95%\n",
      "[ 15/1000]  loss: 2.9963   precision: 4.60%\n",
      "[ 16/1000]  loss: 2.9953   precision: 4.80%\n",
      "[ 17/1000]  loss: 2.9973   precision: 4.85%\n",
      "[ 18/1000]  loss: 2.9967   precision: 4.80%\n",
      "[ 19/1000]  loss: 2.9950   precision: 5.45%\n",
      "[ 20/1000]  loss: 2.9945   precision: 5.05%\n",
      "[ 21/1000]  loss: 2.9959   precision: 5.00%\n",
      "[ 22/1000]  loss: 2.9952   precision: 4.90%\n",
      "[ 23/1000]  loss: 2.9967   precision: 5.20%\n",
      "[ 24/1000]  loss: 2.9964   precision: 4.75%\n",
      "[ 25/1000]  loss: 2.9957   precision: 5.05%\n",
      "[ 26/1000]  loss: 2.9961   precision: 5.10%\n",
      "[ 27/1000]  loss: 2.9961   precision: 5.10%\n",
      "[ 28/1000]  loss: 2.9957   precision: 5.10%\n",
      "[ 29/1000]  loss: 2.9956   precision: 5.20%\n",
      "[ 30/1000]  loss: 2.9955   precision: 5.05%\n",
      "[ 31/1000]  loss: 2.9955   precision: 5.15%\n",
      "[ 32/1000]  loss: 2.9965   precision: 5.00%\n",
      "[ 33/1000]  loss: 2.9976   precision: 5.15%\n",
      "[ 34/1000]  loss: 2.9944   precision: 5.05%\n",
      "[ 35/1000]  loss: 2.9953   precision: 4.95%\n",
      "[ 36/1000]  loss: 2.9950   precision: 5.00%\n",
      "[ 37/1000]  loss: 2.9967   precision: 5.00%\n",
      "[ 38/1000]  loss: 2.9956   precision: 4.90%\n",
      "[ 39/1000]  loss: 2.9956   precision: 5.00%\n",
      "[ 40/1000]  loss: 2.9962   precision: 4.90%\n",
      "[ 41/1000]  loss: 2.9950   precision: 5.15%\n",
      "[ 42/1000]  loss: 2.9951   precision: 4.90%\n",
      "[ 43/1000]  loss: 2.9949   precision: 4.85%\n",
      "[ 44/1000]  loss: 2.9961   precision: 4.90%\n",
      "[ 45/1000]  loss: 2.9940   precision: 4.85%\n",
      "[ 46/1000]  loss: 2.9944   precision: 5.00%\n",
      "[ 47/1000]  loss: 2.9946   precision: 5.25%\n",
      "[ 48/1000]  loss: 2.9955   precision: 5.05%\n",
      "[ 49/1000]  loss: 2.9965   precision: 5.20%\n",
      "[ 50/1000]  loss: 2.9963   precision: 5.10%\n",
      "[ 51/1000]  loss: 2.9958   precision: 5.05%\n",
      "[ 52/1000]  loss: 2.9949   precision: 5.05%\n",
      "[ 53/1000]  loss: 2.9955   precision: 5.40%\n",
      "[ 54/1000]  loss: 2.9942   precision: 5.15%\n",
      "[ 55/1000]  loss: 2.9951   precision: 5.15%\n",
      "[ 56/1000]  loss: 2.9943   precision: 5.40%\n",
      "[ 57/1000]  loss: 2.9960   precision: 4.35%\n",
      "[ 58/1000]  loss: 2.9956   precision: 4.85%\n",
      "[ 59/1000]  loss: 2.9953   precision: 5.00%\n",
      "[ 60/1000]  loss: 2.9949   precision: 4.85%\n",
      "[ 61/1000]  loss: 2.9950   precision: 4.75%\n",
      "[ 62/1000]  loss: 2.9965   precision: 5.05%\n",
      "[ 63/1000]  loss: 2.9950   precision: 5.10%\n",
      "[ 64/1000]  loss: 2.9952   precision: 4.95%\n",
      "[ 65/1000]  loss: 2.9954   precision: 5.15%\n",
      "[ 66/1000]  loss: 2.9952   precision: 5.40%\n",
      "[ 67/1000]  loss: 2.9950   precision: 5.15%\n",
      "[ 68/1000]  loss: 2.9971   precision: 5.30%\n",
      "[ 69/1000]  loss: 2.9951   precision: 5.20%\n",
      "[ 70/1000]  loss: 2.9944   precision: 4.90%\n",
      "[ 71/1000]  loss: 2.9950   precision: 5.40%\n",
      "[ 72/1000]  loss: 2.9955   precision: 5.35%\n",
      "[ 73/1000]  loss: 2.9946   precision: 5.15%\n",
      "[ 74/1000]  loss: 2.9955   precision: 4.90%\n",
      "[ 75/1000]  loss: 2.9958   precision: 5.05%\n",
      "[ 76/1000]  loss: 2.9954   precision: 4.90%\n",
      "[ 77/1000]  loss: 2.9954   precision: 4.95%\n",
      "[ 78/1000]  loss: 2.9951   precision: 4.65%\n",
      "[ 79/1000]  loss: 2.9948   precision: 5.00%\n",
      "[ 80/1000]  loss: 2.9953   precision: 4.80%\n",
      "[ 81/1000]  loss: 2.9958   precision: 4.80%\n",
      "[ 82/1000]  loss: 2.9963   precision: 4.95%\n",
      "[ 83/1000]  loss: 2.9960   precision: 4.60%\n",
      "[ 84/1000]  loss: 2.9943   precision: 4.80%\n",
      "[ 85/1000]  loss: 2.9965   precision: 5.10%\n",
      "[ 86/1000]  loss: 2.9959   precision: 4.60%\n",
      "[ 87/1000]  loss: 2.9959   precision: 5.25%\n",
      "[ 88/1000]  loss: 2.9940   precision: 5.30%\n",
      "[ 89/1000]  loss: 2.9960   precision: 4.80%\n",
      "[ 90/1000]  loss: 2.9959   precision: 4.70%\n",
      "[ 91/1000]  loss: 2.9932   precision: 5.15%\n",
      "[ 92/1000]  loss: 2.9951   precision: 5.00%\n",
      "[ 93/1000]  loss: 2.9943   precision: 4.75%\n",
      "[ 94/1000]  loss: 2.9950   precision: 4.90%\n",
      "[ 95/1000]  loss: 2.9949   precision: 5.25%\n",
      "[ 96/1000]  loss: 2.9944   precision: 4.90%\n",
      "[ 97/1000]  loss: 2.9936   precision: 4.50%\n",
      "[ 98/1000]  loss: 2.9949   precision: 4.65%\n",
      "[ 99/1000]  loss: 2.9959   precision: 5.20%\n",
      "[100/1000]  loss: 2.9951   precision: 6.15%\n",
      "[101/1000]  loss: 2.9930   precision: 4.95%\n",
      "[102/1000]  loss: 2.9948   precision: 4.90%\n",
      "[103/1000]  loss: 2.9967   precision: 5.55%\n",
      "[104/1000]  loss: 2.9949   precision: 4.80%\n",
      "[105/1000]  loss: 2.9948   precision: 4.70%\n",
      "[106/1000]  loss: 2.9937   precision: 4.60%\n",
      "[107/1000]  loss: 2.9945   precision: 4.80%\n",
      "[108/1000]  loss: 2.9948   precision: 4.60%\n",
      "[109/1000]  loss: 2.9942   precision: 5.50%\n",
      "[110/1000]  loss: 2.9932   precision: 4.90%\n",
      "[111/1000]  loss: 2.9965   precision: 5.10%\n",
      "[112/1000]  loss: 2.9951   precision: 4.40%\n",
      "[113/1000]  loss: 2.9937   precision: 4.55%\n",
      "[114/1000]  loss: 2.9945   precision: 5.55%\n",
      "[115/1000]  loss: 2.9937   precision: 4.90%\n",
      "[116/1000]  loss: 2.9950   precision: 4.50%\n",
      "[117/1000]  loss: 2.9974   precision: 5.40%\n",
      "[118/1000]  loss: 2.9953   precision: 4.95%\n",
      "[119/1000]  loss: 2.9929   precision: 4.85%\n",
      "[120/1000]  loss: 2.9956   precision: 5.05%\n",
      "[121/1000]  loss: 2.9956   precision: 5.25%\n",
      "[122/1000]  loss: 2.9933   precision: 4.50%\n",
      "[123/1000]  loss: 2.9943   precision: 4.95%\n",
      "[124/1000]  loss: 2.9926   precision: 5.05%\n",
      "[125/1000]  loss: 2.9965   precision: 5.40%\n",
      "[126/1000]  loss: 2.9945   precision: 4.65%\n",
      "[127/1000]  loss: 2.9949   precision: 4.95%\n",
      "[128/1000]  loss: 2.9952   precision: 4.65%\n",
      "[129/1000]  loss: 2.9954   precision: 4.65%\n",
      "[130/1000]  loss: 2.9945   precision: 5.20%\n",
      "[131/1000]  loss: 2.9960   precision: 4.55%\n",
      "[132/1000]  loss: 2.9944   precision: 5.25%\n",
      "[133/1000]  loss: 2.9938   precision: 4.95%\n",
      "[134/1000]  loss: 2.9956   precision: 5.40%\n",
      "[135/1000]  loss: 2.9945   precision: 4.85%\n",
      "[136/1000]  loss: 2.9949   precision: 4.65%\n",
      "[137/1000]  loss: 2.9941   precision: 5.35%\n",
      "[138/1000]  loss: 2.9959   precision: 5.15%\n",
      "[139/1000]  loss: 2.9965   precision: 5.20%\n",
      "[140/1000]  loss: 2.9943   precision: 4.85%\n",
      "[141/1000]  loss: 2.9969   precision: 4.70%\n",
      "[142/1000]  loss: 2.9983   precision: 5.25%\n",
      "[143/1000]  loss: 2.9969   precision: 5.15%\n",
      "[144/1000]  loss: 2.9943   precision: 5.00%\n",
      "[145/1000]  loss: 2.9961   precision: 4.95%\n",
      "[146/1000]  loss: 2.9942   precision: 4.80%\n",
      "[147/1000]  loss: 2.9948   precision: 4.95%\n",
      "[148/1000]  loss: 2.9942   precision: 5.10%\n",
      "[149/1000]  loss: 2.9942   precision: 4.65%\n",
      "[150/1000]  loss: 2.9951   precision: 4.95%\n",
      "[151/1000]  loss: 2.9931   precision: 5.25%\n",
      "[152/1000]  loss: 2.9949   precision: 5.15%\n",
      "[153/1000]  loss: 2.9937   precision: 5.20%\n",
      "[154/1000]  loss: 2.9963   precision: 5.25%\n",
      "[155/1000]  loss: 2.9957   precision: 5.20%\n",
      "[156/1000]  loss: 2.9963   precision: 5.20%\n",
      "[157/1000]  loss: 2.9956   precision: 4.80%\n",
      "[158/1000]  loss: 2.9939   precision: 4.95%\n",
      "[159/1000]  loss: 2.9933   precision: 4.85%\n",
      "[160/1000]  loss: 2.9956   precision: 4.80%\n",
      "[161/1000]  loss: 2.9975   precision: 5.00%\n",
      "[162/1000]  loss: 2.9949   precision: 5.00%\n",
      "[163/1000]  loss: 2.9932   precision: 4.45%\n",
      "[164/1000]  loss: 2.9965   precision: 4.80%\n",
      "[165/1000]  loss: 2.9949   precision: 5.65%\n",
      "[166/1000]  loss: 2.9949   precision: 4.65%\n",
      "[167/1000]  loss: 2.9948   precision: 5.00%\n",
      "[168/1000]  loss: 2.9914   precision: 4.55%\n",
      "[169/1000]  loss: 2.9967   precision: 5.10%\n",
      "[170/1000]  loss: 2.9958   precision: 5.10%\n",
      "[171/1000]  loss: 2.9969   precision: 5.20%\n",
      "[172/1000]  loss: 2.9957   precision: 5.60%\n",
      "[173/1000]  loss: 2.9962   precision: 5.10%\n",
      "[174/1000]  loss: 2.9969   precision: 4.80%\n",
      "[175/1000]  loss: 2.9936   precision: 5.00%\n",
      "[176/1000]  loss: 2.9936   precision: 5.00%\n",
      "[177/1000]  loss: 2.9922   precision: 5.25%\n",
      "[178/1000]  loss: 2.9951   precision: 4.95%\n",
      "[179/1000]  loss: 2.9961   precision: 4.85%\n",
      "[180/1000]  loss: 2.9959   precision: 5.05%\n",
      "[181/1000]  loss: 2.9923   precision: 5.00%\n",
      "[182/1000]  loss: 2.9949   precision: 5.00%\n",
      "[183/1000]  loss: 2.9934   precision: 5.40%\n",
      "[184/1000]  loss: 2.9941   precision: 4.40%\n",
      "[185/1000]  loss: 2.9957   precision: 5.10%\n",
      "[186/1000]  loss: 2.9953   precision: 4.95%\n",
      "[187/1000]  loss: 2.9948   precision: 4.75%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[188/1000]  loss: 2.9938   precision: 5.20%\n",
      "[189/1000]  loss: 2.9947   precision: 5.10%\n",
      "[190/1000]  loss: 2.9941   precision: 4.90%\n",
      "[191/1000]  loss: 2.9952   precision: 4.35%\n",
      "[192/1000]  loss: 2.9947   precision: 5.15%\n",
      "[193/1000]  loss: 2.9937   precision: 5.45%\n",
      "[194/1000]  loss: 2.9950   precision: 5.15%\n",
      "[195/1000]  loss: 2.9960   precision: 4.85%\n",
      "[196/1000]  loss: 2.9947   precision: 4.55%\n",
      "[197/1000]  loss: 2.9923   precision: 5.15%\n",
      "[198/1000]  loss: 2.9960   precision: 5.00%\n",
      "[199/1000]  loss: 2.9961   precision: 4.95%\n",
      "[200/1000]  loss: 2.9975   precision: 5.35%\n",
      "[201/1000]  loss: 2.9944   precision: 5.75%\n",
      "[202/1000]  loss: 2.9957   precision: 5.25%\n",
      "[203/1000]  loss: 2.9934   precision: 4.90%\n",
      "[204/1000]  loss: 2.9934   precision: 5.35%\n",
      "[205/1000]  loss: 2.9970   precision: 5.25%\n",
      "[206/1000]  loss: 2.9952   precision: 4.75%\n",
      "[207/1000]  loss: 2.9954   precision: 5.30%\n",
      "[208/1000]  loss: 2.9912   precision: 5.00%\n",
      "[209/1000]  loss: 2.9987   precision: 5.15%\n",
      "[210/1000]  loss: 2.9940   precision: 5.15%\n",
      "[211/1000]  loss: 2.9981   precision: 4.50%\n",
      "[212/1000]  loss: 2.9944   precision: 5.10%\n",
      "[213/1000]  loss: 2.9936   precision: 4.80%\n",
      "[214/1000]  loss: 2.9950   precision: 5.25%\n",
      "[215/1000]  loss: 2.9942   precision: 4.55%\n",
      "[216/1000]  loss: 2.9937   precision: 5.35%\n",
      "[217/1000]  loss: 2.9938   precision: 4.05%\n",
      "[218/1000]  loss: 2.9959   precision: 4.60%\n",
      "[219/1000]  loss: 2.9928   precision: 5.10%\n",
      "[220/1000]  loss: 2.9932   precision: 5.50%\n",
      "[221/1000]  loss: 2.9934   precision: 5.35%\n",
      "[222/1000]  loss: 2.9949   precision: 4.85%\n",
      "[223/1000]  loss: 2.9966   precision: 5.00%\n",
      "[224/1000]  loss: 2.9935   precision: 5.40%\n",
      "[225/1000]  loss: 2.9924   precision: 4.85%\n",
      "[226/1000]  loss: 2.9951   precision: 4.85%\n",
      "[227/1000]  loss: 2.9960   precision: 4.90%\n",
      "[228/1000]  loss: 2.9963   precision: 5.10%\n",
      "[229/1000]  loss: 2.9956   precision: 4.90%\n",
      "[230/1000]  loss: 2.9929   precision: 5.00%\n",
      "[231/1000]  loss: 2.9940   precision: 5.50%\n",
      "[232/1000]  loss: 2.9950   precision: 5.05%\n",
      "[233/1000]  loss: 2.9940   precision: 5.20%\n",
      "[234/1000]  loss: 2.9957   precision: 5.25%\n",
      "[235/1000]  loss: 2.9949   precision: 5.15%\n",
      "[236/1000]  loss: 2.9968   precision: 4.00%\n",
      "[237/1000]  loss: 2.9970   precision: 4.55%\n",
      "[238/1000]  loss: 2.9933   precision: 5.00%\n",
      "[239/1000]  loss: 2.9949   precision: 4.20%\n",
      "[240/1000]  loss: 2.9955   precision: 4.60%\n",
      "[241/1000]  loss: 2.9917   precision: 5.20%\n",
      "[242/1000]  loss: 2.9939   precision: 4.75%\n",
      "[243/1000]  loss: 2.9937   precision: 4.90%\n",
      "[244/1000]  loss: 2.9936   precision: 4.40%\n",
      "[245/1000]  loss: 2.9947   precision: 5.05%\n",
      "[246/1000]  loss: 2.9954   precision: 5.85%\n",
      "[247/1000]  loss: 2.9940   precision: 4.85%\n",
      "[248/1000]  loss: 2.9949   precision: 4.75%\n",
      "[249/1000]  loss: 2.9939   precision: 5.05%\n",
      "[250/1000]  loss: 2.9943   precision: 4.75%\n",
      "[251/1000]  loss: 2.9929   precision: 4.80%\n",
      "[252/1000]  loss: 2.9945   precision: 5.05%\n",
      "[253/1000]  loss: 2.9939   precision: 5.50%\n",
      "[254/1000]  loss: 2.9952   precision: 5.00%\n",
      "[255/1000]  loss: 2.9965   precision: 4.85%\n",
      "[256/1000]  loss: 2.9932   precision: 5.35%\n",
      "[257/1000]  loss: 2.9933   precision: 4.70%\n",
      "[258/1000]  loss: 2.9953   precision: 4.45%\n",
      "[259/1000]  loss: 2.9964   precision: 4.95%\n",
      "[260/1000]  loss: 2.9959   precision: 5.60%\n",
      "[261/1000]  loss: 2.9944   precision: 5.75%\n",
      "[262/1000]  loss: 2.9921   precision: 4.90%\n",
      "[263/1000]  loss: 2.9939   precision: 5.10%\n",
      "[264/1000]  loss: 2.9934   precision: 5.95%\n",
      "[265/1000]  loss: 2.9935   precision: 5.50%\n",
      "[266/1000]  loss: 2.9948   precision: 5.40%\n",
      "[267/1000]  loss: 2.9939   precision: 5.10%\n",
      "[268/1000]  loss: 2.9943   precision: 4.85%\n",
      "[269/1000]  loss: 2.9955   precision: 4.60%\n",
      "[270/1000]  loss: 2.9919   precision: 4.40%\n",
      "[271/1000]  loss: 2.9938   precision: 5.10%\n",
      "[272/1000]  loss: 2.9939   precision: 5.25%\n",
      "[273/1000]  loss: 2.9966   precision: 4.80%\n",
      "[274/1000]  loss: 2.9941   precision: 5.20%\n",
      "[275/1000]  loss: 2.9965   precision: 5.05%\n",
      "[276/1000]  loss: 2.9935   precision: 4.75%\n",
      "[277/1000]  loss: 2.9961   precision: 5.75%\n",
      "[278/1000]  loss: 2.9936   precision: 4.90%\n",
      "[279/1000]  loss: 2.9929   precision: 4.25%\n",
      "[280/1000]  loss: 2.9926   precision: 4.75%\n",
      "[281/1000]  loss: 2.9982   precision: 5.30%\n",
      "[282/1000]  loss: 2.9932   precision: 4.85%\n",
      "[283/1000]  loss: 2.9955   precision: 4.65%\n",
      "[284/1000]  loss: 2.9926   precision: 5.45%\n",
      "[285/1000]  loss: 2.9961   precision: 5.25%\n",
      "[286/1000]  loss: 2.9951   precision: 4.60%\n",
      "[287/1000]  loss: 2.9928   precision: 5.35%\n",
      "[288/1000]  loss: 2.9963   precision: 5.25%\n",
      "[289/1000]  loss: 2.9946   precision: 4.70%\n",
      "[290/1000]  loss: 2.9923   precision: 4.55%\n",
      "[291/1000]  loss: 2.9949   precision: 4.55%\n",
      "[292/1000]  loss: 2.9951   precision: 4.45%\n",
      "[293/1000]  loss: 2.9939   precision: 5.45%\n",
      "[294/1000]  loss: 2.9938   precision: 5.00%\n",
      "[295/1000]  loss: 2.9963   precision: 5.05%\n",
      "[296/1000]  loss: 2.9939   precision: 5.05%\n",
      "[297/1000]  loss: 2.9947   precision: 4.80%\n",
      "[298/1000]  loss: 2.9919   precision: 5.40%\n",
      "[299/1000]  loss: 2.9944   precision: 4.85%\n",
      "[300/1000]  loss: 2.9946   precision: 5.05%\n",
      "[301/1000]  loss: 2.9942   precision: 5.15%\n",
      "[302/1000]  loss: 2.9916   precision: 5.10%\n",
      "[303/1000]  loss: 2.9950   precision: 5.55%\n",
      "[304/1000]  loss: 2.9964   precision: 5.10%\n",
      "[305/1000]  loss: 2.9956   precision: 4.95%\n",
      "[306/1000]  loss: 2.9961   precision: 5.05%\n",
      "[307/1000]  loss: 2.9953   precision: 5.60%\n",
      "[308/1000]  loss: 2.9909   precision: 4.75%\n",
      "[309/1000]  loss: 2.9944   precision: 5.40%\n",
      "[310/1000]  loss: 2.9932   precision: 4.95%\n",
      "[311/1000]  loss: 2.9918   precision: 4.90%\n",
      "[312/1000]  loss: 2.9983   precision: 5.15%\n",
      "[313/1000]  loss: 2.9942   precision: 4.30%\n",
      "[314/1000]  loss: 2.9949   precision: 5.05%\n",
      "[315/1000]  loss: 2.9933   precision: 5.75%\n",
      "[316/1000]  loss: 2.9945   precision: 5.40%\n",
      "[317/1000]  loss: 2.9975   precision: 5.25%\n",
      "[318/1000]  loss: 2.9933   precision: 4.70%\n",
      "[319/1000]  loss: 2.9927   precision: 5.40%\n",
      "[320/1000]  loss: 2.9937   precision: 5.35%\n",
      "[321/1000]  loss: 2.9958   precision: 4.70%\n",
      "[322/1000]  loss: 2.9955   precision: 4.65%\n",
      "[323/1000]  loss: 2.9944   precision: 5.20%\n",
      "[324/1000]  loss: 2.9959   precision: 5.40%\n",
      "[325/1000]  loss: 2.9934   precision: 5.25%\n",
      "[326/1000]  loss: 2.9946   precision: 5.10%\n",
      "[327/1000]  loss: 2.9923   precision: 4.85%\n",
      "[328/1000]  loss: 2.9960   precision: 4.40%\n",
      "[329/1000]  loss: 2.9925   precision: 4.80%\n",
      "[330/1000]  loss: 2.9943   precision: 5.20%\n",
      "[331/1000]  loss: 2.9922   precision: 5.30%\n",
      "[332/1000]  loss: 2.9918   precision: 5.00%\n",
      "[333/1000]  loss: 2.9946   precision: 4.85%\n",
      "[334/1000]  loss: 2.9947   precision: 4.60%\n",
      "[335/1000]  loss: 2.9922   precision: 5.00%\n",
      "[336/1000]  loss: 2.9954   precision: 5.10%\n",
      "[337/1000]  loss: 2.9931   precision: 5.30%\n",
      "[338/1000]  loss: 2.9923   precision: 4.75%\n",
      "[339/1000]  loss: 2.9962   precision: 4.90%\n",
      "[340/1000]  loss: 2.9952   precision: 4.65%\n",
      "[341/1000]  loss: 2.9968   precision: 5.20%\n",
      "[342/1000]  loss: 2.9943   precision: 4.85%\n",
      "[343/1000]  loss: 2.9939   precision: 4.90%\n",
      "[344/1000]  loss: 2.9972   precision: 5.50%\n",
      "[345/1000]  loss: 2.9948   precision: 5.20%\n",
      "[346/1000]  loss: 2.9924   precision: 5.55%\n",
      "[347/1000]  loss: 2.9937   precision: 4.40%\n",
      "[348/1000]  loss: 2.9952   precision: 5.35%\n",
      "[349/1000]  loss: 2.9943   precision: 4.70%\n",
      "[350/1000]  loss: 2.9942   precision: 5.40%\n",
      "[351/1000]  loss: 2.9940   precision: 4.40%\n",
      "[352/1000]  loss: 2.9927   precision: 5.40%\n",
      "[353/1000]  loss: 2.9957   precision: 4.85%\n",
      "[354/1000]  loss: 2.9959   precision: 5.15%\n",
      "[355/1000]  loss: 2.9922   precision: 5.30%\n",
      "[356/1000]  loss: 2.9957   precision: 4.60%\n",
      "[357/1000]  loss: 2.9937   precision: 5.80%\n",
      "[358/1000]  loss: 2.9926   precision: 5.00%\n",
      "[359/1000]  loss: 2.9951   precision: 4.95%\n",
      "[360/1000]  loss: 2.9922   precision: 4.30%\n",
      "[361/1000]  loss: 2.9938   precision: 5.40%\n",
      "[362/1000]  loss: 2.9963   precision: 5.05%\n",
      "[363/1000]  loss: 2.9944   precision: 5.10%\n",
      "[364/1000]  loss: 2.9959   precision: 4.90%\n",
      "[365/1000]  loss: 2.9926   precision: 5.05%\n",
      "[366/1000]  loss: 2.9938   precision: 4.75%\n",
      "[367/1000]  loss: 2.9903   precision: 5.00%\n",
      "[368/1000]  loss: 2.9966   precision: 4.65%\n",
      "[369/1000]  loss: 2.9960   precision: 5.20%\n",
      "[370/1000]  loss: 2.9947   precision: 4.75%\n",
      "[371/1000]  loss: 2.9927   precision: 5.15%\n",
      "[372/1000]  loss: 2.9929   precision: 4.95%\n",
      "[373/1000]  loss: 2.9911   precision: 4.55%\n",
      "[374/1000]  loss: 2.9937   precision: 5.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[375/1000]  loss: 2.9927   precision: 5.70%\n",
      "[376/1000]  loss: 2.9952   precision: 4.95%\n",
      "[377/1000]  loss: 2.9981   precision: 4.80%\n",
      "[378/1000]  loss: 2.9933   precision: 5.40%\n",
      "[379/1000]  loss: 2.9931   precision: 4.95%\n",
      "[380/1000]  loss: 2.9968   precision: 4.45%\n",
      "[381/1000]  loss: 2.9933   precision: 4.95%\n",
      "[382/1000]  loss: 2.9947   precision: 5.00%\n",
      "[383/1000]  loss: 2.9931   precision: 4.65%\n",
      "[384/1000]  loss: 2.9945   precision: 4.90%\n",
      "[385/1000]  loss: 2.9913   precision: 4.95%\n",
      "[386/1000]  loss: 2.9960   precision: 5.20%\n",
      "[387/1000]  loss: 2.9935   precision: 5.35%\n",
      "[388/1000]  loss: 2.9937   precision: 4.95%\n",
      "[389/1000]  loss: 2.9959   precision: 4.95%\n",
      "[390/1000]  loss: 2.9949   precision: 4.65%\n",
      "[391/1000]  loss: 2.9955   precision: 5.05%\n",
      "[392/1000]  loss: 2.9944   precision: 4.70%\n",
      "[393/1000]  loss: 2.9921   precision: 5.40%\n",
      "[394/1000]  loss: 2.9942   precision: 5.40%\n",
      "[395/1000]  loss: 2.9930   precision: 4.95%\n",
      "[396/1000]  loss: 2.9936   precision: 4.95%\n",
      "[397/1000]  loss: 2.9942   precision: 4.95%\n",
      "[398/1000]  loss: 2.9948   precision: 5.15%\n",
      "[399/1000]  loss: 2.9920   precision: 5.05%\n",
      "[400/1000]  loss: 2.9950   precision: 5.35%\n",
      "[401/1000]  loss: 2.9960   precision: 5.15%\n",
      "[402/1000]  loss: 2.9967   precision: 4.95%\n",
      "[403/1000]  loss: 2.9943   precision: 4.90%\n",
      "[404/1000]  loss: 2.9904   precision: 4.85%\n",
      "[405/1000]  loss: 2.9971   precision: 5.05%\n",
      "[406/1000]  loss: 2.9936   precision: 5.20%\n",
      "[407/1000]  loss: 2.9964   precision: 5.30%\n",
      "[408/1000]  loss: 2.9958   precision: 5.25%\n",
      "[409/1000]  loss: 2.9998   precision: 4.95%\n",
      "[410/1000]  loss: 2.9901   precision: 5.15%\n",
      "[411/1000]  loss: 2.9939   precision: 4.75%\n",
      "[412/1000]  loss: 2.9936   precision: 5.55%\n",
      "[413/1000]  loss: 2.9895   precision: 4.75%\n",
      "[414/1000]  loss: 2.9926   precision: 5.05%\n",
      "[415/1000]  loss: 2.9944   precision: 4.55%\n",
      "[416/1000]  loss: 2.9952   precision: 5.05%\n",
      "[417/1000]  loss: 2.9966   precision: 4.85%\n",
      "[418/1000]  loss: 2.9958   precision: 4.65%\n",
      "[419/1000]  loss: 2.9956   precision: 4.90%\n",
      "[420/1000]  loss: 2.9950   precision: 5.40%\n",
      "[421/1000]  loss: 2.9940   precision: 5.35%\n",
      "[422/1000]  loss: 2.9949   precision: 5.05%\n",
      "[423/1000]  loss: 2.9971   precision: 4.70%\n",
      "[424/1000]  loss: 2.9921   precision: 5.20%\n",
      "[425/1000]  loss: 2.9935   precision: 4.75%\n",
      "[426/1000]  loss: 2.9943   precision: 4.95%\n",
      "[427/1000]  loss: 2.9930   precision: 5.70%\n",
      "[428/1000]  loss: 2.9967   precision: 5.00%\n",
      "[429/1000]  loss: 2.9971   precision: 5.05%\n",
      "[430/1000]  loss: 2.9911   precision: 4.95%\n",
      "[431/1000]  loss: 2.9959   precision: 5.15%\n",
      "[432/1000]  loss: 2.9933   precision: 5.10%\n",
      "[433/1000]  loss: 2.9954   precision: 4.60%\n",
      "[434/1000]  loss: 2.9916   precision: 4.80%\n",
      "[435/1000]  loss: 2.9956   precision: 5.30%\n",
      "[436/1000]  loss: 2.9930   precision: 5.15%\n",
      "[437/1000]  loss: 2.9941   precision: 4.95%\n",
      "[438/1000]  loss: 2.9949   precision: 5.10%\n",
      "[439/1000]  loss: 2.9929   precision: 5.15%\n",
      "[440/1000]  loss: 2.9911   precision: 5.05%\n",
      "[441/1000]  loss: 2.9939   precision: 5.35%\n",
      "[442/1000]  loss: 2.9957   precision: 5.25%\n",
      "[443/1000]  loss: 2.9951   precision: 5.30%\n",
      "[444/1000]  loss: 2.9958   precision: 4.60%\n",
      "[445/1000]  loss: 2.9918   precision: 5.15%\n",
      "[446/1000]  loss: 2.9923   precision: 5.05%\n",
      "[447/1000]  loss: 2.9920   precision: 5.10%\n",
      "[448/1000]  loss: 2.9939   precision: 4.70%\n",
      "[449/1000]  loss: 2.9959   precision: 5.00%\n",
      "[450/1000]  loss: 2.9938   precision: 4.85%\n",
      "[451/1000]  loss: 2.9937   precision: 5.10%\n",
      "[452/1000]  loss: 2.9917   precision: 5.15%\n",
      "[453/1000]  loss: 2.9965   precision: 4.80%\n",
      "[454/1000]  loss: 2.9932   precision: 5.25%\n",
      "[455/1000]  loss: 2.9960   precision: 5.15%\n",
      "[456/1000]  loss: 2.9931   precision: 4.90%\n",
      "[457/1000]  loss: 2.9913   precision: 4.95%\n",
      "[458/1000]  loss: 2.9939   precision: 5.00%\n",
      "[459/1000]  loss: 2.9931   precision: 4.85%\n",
      "[460/1000]  loss: 2.9899   precision: 5.10%\n",
      "[461/1000]  loss: 2.9943   precision: 4.55%\n",
      "[462/1000]  loss: 2.9911   precision: 4.75%\n",
      "[463/1000]  loss: 2.9967   precision: 5.00%\n",
      "[464/1000]  loss: 2.9986   precision: 5.10%\n",
      "[465/1000]  loss: 2.9926   precision: 5.15%\n",
      "[466/1000]  loss: 2.9909   precision: 5.25%\n",
      "[467/1000]  loss: 2.9935   precision: 4.90%\n",
      "[468/1000]  loss: 2.9940   precision: 5.30%\n",
      "[469/1000]  loss: 2.9956   precision: 4.75%\n",
      "[470/1000]  loss: 2.9951   precision: 5.20%\n",
      "[471/1000]  loss: 2.9959   precision: 4.90%\n",
      "[472/1000]  loss: 2.9951   precision: 5.05%\n",
      "[473/1000]  loss: 2.9938   precision: 5.05%\n",
      "[474/1000]  loss: 2.9950   precision: 4.75%\n",
      "[475/1000]  loss: 2.9946   precision: 4.95%\n",
      "[476/1000]  loss: 2.9923   precision: 4.95%\n",
      "[477/1000]  loss: 2.9935   precision: 5.20%\n",
      "[478/1000]  loss: 2.9955   precision: 5.00%\n",
      "[479/1000]  loss: 2.9909   precision: 5.05%\n",
      "[480/1000]  loss: 2.9928   precision: 5.55%\n",
      "[481/1000]  loss: 2.9925   precision: 4.70%\n",
      "[482/1000]  loss: 2.9957   precision: 5.25%\n",
      "[483/1000]  loss: 2.9935   precision: 4.75%\n",
      "[484/1000]  loss: 2.9935   precision: 4.90%\n",
      "[485/1000]  loss: 2.9924   precision: 5.20%\n",
      "[486/1000]  loss: 2.9942   precision: 4.95%\n",
      "[487/1000]  loss: 2.9933   precision: 5.00%\n",
      "[488/1000]  loss: 2.9947   precision: 4.60%\n",
      "[489/1000]  loss: 2.9928   precision: 5.20%\n",
      "[490/1000]  loss: 2.9944   precision: 5.60%\n",
      "[491/1000]  loss: 2.9923   precision: 5.00%\n",
      "[492/1000]  loss: 2.9958   precision: 4.65%\n",
      "[493/1000]  loss: 2.9884   precision: 5.55%\n",
      "[494/1000]  loss: 2.9950   precision: 4.55%\n",
      "[495/1000]  loss: 2.9904   precision: 5.10%\n",
      "[496/1000]  loss: 2.9942   precision: 5.10%\n",
      "[497/1000]  loss: 2.9936   precision: 5.25%\n",
      "[498/1000]  loss: 2.9928   precision: 5.15%\n",
      "[499/1000]  loss: 2.9922   precision: 4.90%\n",
      "[500/1000]  loss: 2.9884   precision: 4.80%\n",
      "[501/1000]  loss: 2.9982   precision: 5.20%\n",
      "[502/1000]  loss: 2.9943   precision: 4.90%\n",
      "[503/1000]  loss: 2.9941   precision: 4.50%\n",
      "[504/1000]  loss: 2.9904   precision: 4.75%\n",
      "[505/1000]  loss: 2.9927   precision: 4.75%\n",
      "[506/1000]  loss: 2.9917   precision: 4.95%\n",
      "[507/1000]  loss: 2.9951   precision: 5.10%\n",
      "[508/1000]  loss: 2.9933   precision: 5.20%\n",
      "[509/1000]  loss: 2.9930   precision: 4.80%\n",
      "[510/1000]  loss: 2.9946   precision: 5.10%\n",
      "[511/1000]  loss: 2.9955   precision: 4.85%\n",
      "[512/1000]  loss: 2.9953   precision: 5.35%\n",
      "[513/1000]  loss: 2.9931   precision: 5.15%\n",
      "[514/1000]  loss: 2.9959   precision: 5.25%\n",
      "[515/1000]  loss: 2.9950   precision: 4.65%\n",
      "[516/1000]  loss: 2.9932   precision: 4.50%\n",
      "[517/1000]  loss: 2.9926   precision: 4.50%\n",
      "[518/1000]  loss: 2.9975   precision: 5.35%\n",
      "[519/1000]  loss: 2.9936   precision: 4.80%\n",
      "[520/1000]  loss: 2.9955   precision: 5.45%\n",
      "[521/1000]  loss: 2.9933   precision: 5.35%\n",
      "[522/1000]  loss: 2.9921   precision: 5.00%\n",
      "[523/1000]  loss: 2.9933   precision: 5.00%\n",
      "[524/1000]  loss: 2.9923   precision: 4.70%\n",
      "[525/1000]  loss: 2.9933   precision: 4.85%\n",
      "[526/1000]  loss: 2.9942   precision: 4.85%\n",
      "[527/1000]  loss: 2.9934   precision: 4.95%\n",
      "[528/1000]  loss: 2.9956   precision: 4.95%\n",
      "[529/1000]  loss: 2.9924   precision: 4.95%\n",
      "[530/1000]  loss: 2.9967   precision: 5.00%\n",
      "[531/1000]  loss: 2.9931   precision: 5.05%\n",
      "[532/1000]  loss: 2.9953   precision: 5.20%\n",
      "[533/1000]  loss: 2.9932   precision: 5.10%\n",
      "[534/1000]  loss: 2.9937   precision: 4.85%\n",
      "[535/1000]  loss: 2.9924   precision: 4.90%\n",
      "[536/1000]  loss: 2.9914   precision: 4.75%\n",
      "[537/1000]  loss: 2.9933   precision: 5.15%\n",
      "[538/1000]  loss: 2.9944   precision: 5.10%\n",
      "[539/1000]  loss: 2.9918   precision: 4.90%\n",
      "[540/1000]  loss: 2.9924   precision: 5.15%\n",
      "[541/1000]  loss: 2.9943   precision: 4.75%\n",
      "[542/1000]  loss: 2.9917   precision: 5.25%\n",
      "[543/1000]  loss: 2.9947   precision: 5.25%\n",
      "[544/1000]  loss: 2.9917   precision: 4.95%\n",
      "[545/1000]  loss: 2.9929   precision: 5.15%\n",
      "[546/1000]  loss: 2.9923   precision: 5.10%\n",
      "[547/1000]  loss: 2.9929   precision: 5.20%\n",
      "[548/1000]  loss: 2.9948   precision: 4.95%\n",
      "[549/1000]  loss: 2.9924   precision: 5.00%\n",
      "[550/1000]  loss: 2.9965   precision: 5.00%\n",
      "[551/1000]  loss: 2.9935   precision: 5.20%\n",
      "[552/1000]  loss: 2.9934   precision: 5.00%\n",
      "[553/1000]  loss: 2.9913   precision: 5.05%\n",
      "[554/1000]  loss: 2.9934   precision: 4.80%\n",
      "[555/1000]  loss: 2.9922   precision: 5.10%\n",
      "[556/1000]  loss: 2.9944   precision: 4.60%\n",
      "[557/1000]  loss: 2.9919   precision: 4.80%\n",
      "[558/1000]  loss: 2.9945   precision: 5.40%\n",
      "[559/1000]  loss: 2.9971   precision: 4.80%\n",
      "[560/1000]  loss: 2.9919   precision: 4.80%\n",
      "[561/1000]  loss: 2.9963   precision: 5.05%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[562/1000]  loss: 2.9959   precision: 5.20%\n",
      "[563/1000]  loss: 2.9937   precision: 5.25%\n",
      "[564/1000]  loss: 2.9937   precision: 4.65%\n",
      "[565/1000]  loss: 2.9935   precision: 5.00%\n",
      "[566/1000]  loss: 2.9936   precision: 5.15%\n",
      "[567/1000]  loss: 2.9950   precision: 5.10%\n",
      "[568/1000]  loss: 2.9940   precision: 5.10%\n",
      "[569/1000]  loss: 2.9961   precision: 5.95%\n",
      "[570/1000]  loss: 2.9977   precision: 4.95%\n",
      "[571/1000]  loss: 2.9945   precision: 4.75%\n",
      "[572/1000]  loss: 2.9931   precision: 5.25%\n",
      "[573/1000]  loss: 2.9921   precision: 4.70%\n",
      "[574/1000]  loss: 2.9942   precision: 5.30%\n",
      "[575/1000]  loss: 2.9956   precision: 4.75%\n",
      "[576/1000]  loss: 2.9934   precision: 5.35%\n",
      "[577/1000]  loss: 2.9920   precision: 5.15%\n",
      "[578/1000]  loss: 2.9933   precision: 4.90%\n",
      "[579/1000]  loss: 2.9937   precision: 5.20%\n",
      "[580/1000]  loss: 2.9939   precision: 5.05%\n",
      "[581/1000]  loss: 2.9932   precision: 4.75%\n",
      "[582/1000]  loss: 2.9926   precision: 5.15%\n",
      "[583/1000]  loss: 2.9921   precision: 5.30%\n",
      "[584/1000]  loss: 2.9951   precision: 5.20%\n",
      "[585/1000]  loss: 2.9917   precision: 5.30%\n",
      "[586/1000]  loss: 2.9923   precision: 4.90%\n",
      "[587/1000]  loss: 2.9947   precision: 5.05%\n",
      "[588/1000]  loss: 2.9922   precision: 4.85%\n",
      "[589/1000]  loss: 2.9951   precision: 5.00%\n",
      "[590/1000]  loss: 2.9949   precision: 4.75%\n",
      "[591/1000]  loss: 2.9914   precision: 4.80%\n",
      "[592/1000]  loss: 2.9928   precision: 5.00%\n",
      "[593/1000]  loss: 2.9943   precision: 4.60%\n",
      "[594/1000]  loss: 2.9936   precision: 5.45%\n",
      "[595/1000]  loss: 2.9893   precision: 5.00%\n",
      "[596/1000]  loss: 2.9914   precision: 5.10%\n",
      "[597/1000]  loss: 2.9930   precision: 5.00%\n",
      "[598/1000]  loss: 2.9915   precision: 5.05%\n",
      "[599/1000]  loss: 2.9940   precision: 5.00%\n",
      "[600/1000]  loss: 2.9932   precision: 4.90%\n",
      "[601/1000]  loss: 2.9924   precision: 5.20%\n",
      "[602/1000]  loss: 2.9897   precision: 5.20%\n",
      "[603/1000]  loss: 2.9980   precision: 4.70%\n",
      "[604/1000]  loss: 2.9947   precision: 5.10%\n",
      "[605/1000]  loss: 2.9921   precision: 4.90%\n",
      "[606/1000]  loss: 2.9931   precision: 4.95%\n",
      "[607/1000]  loss: 2.9911   precision: 5.10%\n",
      "[608/1000]  loss: 2.9954   precision: 5.10%\n",
      "[609/1000]  loss: 2.9924   precision: 5.15%\n",
      "[610/1000]  loss: 2.9952   precision: 4.90%\n",
      "[611/1000]  loss: 2.9943   precision: 4.90%\n",
      "[612/1000]  loss: 2.9941   precision: 5.05%\n",
      "[613/1000]  loss: 2.9924   precision: 5.05%\n",
      "[614/1000]  loss: 2.9931   precision: 5.10%\n",
      "[615/1000]  loss: 2.9893   precision: 5.00%\n",
      "[616/1000]  loss: 2.9907   precision: 4.75%\n",
      "[617/1000]  loss: 2.9912   precision: 4.85%\n",
      "[618/1000]  loss: 2.9933   precision: 5.00%\n",
      "[619/1000]  loss: 2.9937   precision: 5.05%\n",
      "[620/1000]  loss: 2.9944   precision: 5.25%\n",
      "[621/1000]  loss: 2.9929   precision: 5.35%\n",
      "[622/1000]  loss: 2.9935   precision: 5.40%\n",
      "[623/1000]  loss: 2.9975   precision: 5.05%\n",
      "[624/1000]  loss: 2.9938   precision: 4.95%\n",
      "[625/1000]  loss: 2.9927   precision: 5.10%\n",
      "[626/1000]  loss: 2.9930   precision: 5.45%\n",
      "[627/1000]  loss: 2.9953   precision: 5.05%\n",
      "[628/1000]  loss: 2.9948   precision: 4.70%\n",
      "[629/1000]  loss: 2.9928   precision: 5.05%\n",
      "[630/1000]  loss: 2.9910   precision: 5.00%\n",
      "[631/1000]  loss: 2.9890   precision: 5.30%\n",
      "[632/1000]  loss: 2.9934   precision: 5.25%\n",
      "[633/1000]  loss: 2.9944   precision: 4.95%\n",
      "[634/1000]  loss: 2.9937   precision: 4.75%\n",
      "[635/1000]  loss: 2.9943   precision: 5.25%\n",
      "[636/1000]  loss: 2.9942   precision: 5.15%\n",
      "[637/1000]  loss: 2.9931   precision: 5.10%\n",
      "[638/1000]  loss: 2.9908   precision: 5.10%\n",
      "[639/1000]  loss: 2.9924   precision: 5.15%\n",
      "[640/1000]  loss: 2.9947   precision: 5.25%\n",
      "[641/1000]  loss: 2.9925   precision: 4.65%\n",
      "[642/1000]  loss: 2.9915   precision: 4.45%\n",
      "[643/1000]  loss: 2.9938   precision: 5.00%\n",
      "[644/1000]  loss: 2.9949   precision: 5.15%\n",
      "[645/1000]  loss: 2.9910   precision: 5.35%\n",
      "[646/1000]  loss: 2.9954   precision: 4.85%\n",
      "[647/1000]  loss: 2.9956   precision: 4.75%\n",
      "[648/1000]  loss: 2.9921   precision: 4.95%\n",
      "[649/1000]  loss: 2.9918   precision: 5.25%\n",
      "[650/1000]  loss: 2.9908   precision: 5.05%\n",
      "[651/1000]  loss: 2.9929   precision: 4.85%\n",
      "[652/1000]  loss: 2.9902   precision: 4.75%\n",
      "[653/1000]  loss: 2.9943   precision: 4.80%\n",
      "[654/1000]  loss: 2.9959   precision: 5.00%\n",
      "[655/1000]  loss: 2.9955   precision: 5.10%\n",
      "[656/1000]  loss: 2.9924   precision: 4.95%\n",
      "[657/1000]  loss: 2.9947   precision: 4.80%\n",
      "[658/1000]  loss: 2.9940   precision: 5.35%\n",
      "[659/1000]  loss: 2.9943   precision: 4.75%\n",
      "[660/1000]  loss: 2.9924   precision: 4.95%\n",
      "[661/1000]  loss: 2.9919   precision: 5.20%\n",
      "[662/1000]  loss: 2.9971   precision: 4.75%\n",
      "[663/1000]  loss: 2.9929   precision: 5.15%\n",
      "[664/1000]  loss: 2.9926   precision: 4.85%\n",
      "[665/1000]  loss: 2.9930   precision: 5.05%\n",
      "[666/1000]  loss: 2.9940   precision: 5.25%\n",
      "[667/1000]  loss: 2.9949   precision: 5.10%\n",
      "[668/1000]  loss: 2.9934   precision: 5.10%\n",
      "[669/1000]  loss: 2.9939   precision: 5.30%\n",
      "[670/1000]  loss: 2.9942   precision: 5.05%\n",
      "[671/1000]  loss: 2.9922   precision: 4.95%\n",
      "[672/1000]  loss: 2.9953   precision: 4.85%\n",
      "[673/1000]  loss: 2.9930   precision: 4.85%\n",
      "[674/1000]  loss: 2.9946   precision: 5.15%\n",
      "[675/1000]  loss: 2.9927   precision: 4.75%\n",
      "[676/1000]  loss: 2.9920   precision: 5.25%\n",
      "[677/1000]  loss: 2.9906   precision: 5.15%\n",
      "[678/1000]  loss: 2.9897   precision: 5.30%\n",
      "[679/1000]  loss: 2.9933   precision: 5.00%\n",
      "[680/1000]  loss: 2.9919   precision: 5.15%\n",
      "[681/1000]  loss: 2.9952   precision: 5.05%\n",
      "[682/1000]  loss: 2.9928   precision: 4.85%\n",
      "[683/1000]  loss: 2.9924   precision: 5.10%\n",
      "[684/1000]  loss: 2.9919   precision: 4.95%\n",
      "[685/1000]  loss: 2.9915   precision: 5.25%\n",
      "[686/1000]  loss: 2.9932   precision: 5.00%\n",
      "[687/1000]  loss: 2.9949   precision: 5.00%\n",
      "[688/1000]  loss: 2.9918   precision: 4.85%\n",
      "[689/1000]  loss: 2.9922   precision: 4.80%\n",
      "[690/1000]  loss: 2.9911   precision: 4.85%\n",
      "[691/1000]  loss: 2.9953   precision: 4.75%\n",
      "[692/1000]  loss: 2.9911   precision: 5.00%\n",
      "[693/1000]  loss: 2.9935   precision: 4.85%\n",
      "[694/1000]  loss: 2.9948   precision: 5.10%\n",
      "[695/1000]  loss: 2.9934   precision: 5.15%\n",
      "[696/1000]  loss: 2.9923   precision: 4.75%\n",
      "[697/1000]  loss: 2.9951   precision: 5.10%\n",
      "[698/1000]  loss: 2.9930   precision: 5.20%\n",
      "[699/1000]  loss: 2.9908   precision: 5.20%\n",
      "[700/1000]  loss: 2.9948   precision: 5.00%\n",
      "[701/1000]  loss: 2.9928   precision: 5.15%\n",
      "[702/1000]  loss: 2.9906   precision: 5.05%\n",
      "[703/1000]  loss: 2.9922   precision: 4.90%\n",
      "[704/1000]  loss: 2.9943   precision: 5.65%\n",
      "[705/1000]  loss: 2.9918   precision: 4.60%\n",
      "[706/1000]  loss: 2.9915   precision: 4.90%\n",
      "[707/1000]  loss: 2.9941   precision: 4.90%\n",
      "[708/1000]  loss: 2.9933   precision: 5.50%\n",
      "[709/1000]  loss: 2.9959   precision: 5.05%\n",
      "[710/1000]  loss: 2.9936   precision: 4.65%\n",
      "[711/1000]  loss: 2.9926   precision: 4.90%\n",
      "[712/1000]  loss: 2.9915   precision: 5.05%\n",
      "[713/1000]  loss: 2.9934   precision: 4.90%\n",
      "[714/1000]  loss: 2.9932   precision: 5.30%\n",
      "[715/1000]  loss: 2.9921   precision: 5.05%\n",
      "[716/1000]  loss: 2.9927   precision: 5.35%\n",
      "[717/1000]  loss: 2.9949   precision: 5.15%\n",
      "[718/1000]  loss: 2.9906   precision: 4.85%\n",
      "[719/1000]  loss: 2.9909   precision: 5.10%\n",
      "[720/1000]  loss: 2.9919   precision: 5.25%\n",
      "[721/1000]  loss: 2.9962   precision: 5.10%\n",
      "[722/1000]  loss: 2.9936   precision: 4.90%\n",
      "[723/1000]  loss: 2.9944   precision: 5.55%\n",
      "[724/1000]  loss: 2.9926   precision: 4.55%\n",
      "[725/1000]  loss: 2.9932   precision: 5.30%\n",
      "[726/1000]  loss: 2.9936   precision: 5.05%\n",
      "[727/1000]  loss: 2.9937   precision: 5.05%\n",
      "[728/1000]  loss: 2.9987   precision: 5.00%\n",
      "[729/1000]  loss: 2.9956   precision: 5.05%\n",
      "[730/1000]  loss: 2.9964   precision: 4.85%\n",
      "[731/1000]  loss: 2.9935   precision: 4.90%\n",
      "[732/1000]  loss: 2.9892   precision: 5.10%\n",
      "[733/1000]  loss: 2.9926   precision: 5.25%\n",
      "[734/1000]  loss: 2.9902   precision: 4.95%\n",
      "[735/1000]  loss: 2.9953   precision: 4.90%\n",
      "[736/1000]  loss: 2.9919   precision: 4.80%\n",
      "[737/1000]  loss: 2.9941   precision: 5.20%\n",
      "[738/1000]  loss: 2.9923   precision: 5.10%\n",
      "[739/1000]  loss: 2.9942   precision: 5.10%\n",
      "[740/1000]  loss: 2.9980   precision: 5.10%\n",
      "[741/1000]  loss: 2.9906   precision: 4.95%\n",
      "[742/1000]  loss: 2.9933   precision: 5.40%\n",
      "[743/1000]  loss: 2.9923   precision: 5.00%\n",
      "[744/1000]  loss: 2.9917   precision: 5.35%\n",
      "[745/1000]  loss: 2.9919   precision: 4.45%\n",
      "[746/1000]  loss: 2.9958   precision: 4.60%\n",
      "[747/1000]  loss: 2.9937   precision: 4.40%\n",
      "[748/1000]  loss: 2.9941   precision: 4.75%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[749/1000]  loss: 2.9944   precision: 4.70%\n",
      "[750/1000]  loss: 2.9938   precision: 5.15%\n",
      "[751/1000]  loss: 2.9917   precision: 5.25%\n",
      "[752/1000]  loss: 2.9900   precision: 4.70%\n",
      "[753/1000]  loss: 2.9915   precision: 5.40%\n",
      "[754/1000]  loss: 2.9940   precision: 4.90%\n",
      "[755/1000]  loss: 2.9983   precision: 4.80%\n",
      "[756/1000]  loss: 2.9952   precision: 5.10%\n",
      "[757/1000]  loss: 2.9942   precision: 4.15%\n",
      "[758/1000]  loss: 2.9951   precision: 5.15%\n",
      "[759/1000]  loss: 2.9906   precision: 5.05%\n",
      "[760/1000]  loss: 2.9924   precision: 5.20%\n",
      "[761/1000]  loss: 2.9974   precision: 5.35%\n",
      "[762/1000]  loss: 2.9936   precision: 4.80%\n",
      "[763/1000]  loss: 2.9926   precision: 5.05%\n",
      "[764/1000]  loss: 2.9901   precision: 5.25%\n",
      "[765/1000]  loss: 2.9976   precision: 4.75%\n",
      "[766/1000]  loss: 2.9911   precision: 5.10%\n",
      "[767/1000]  loss: 2.9924   precision: 4.40%\n",
      "[768/1000]  loss: 2.9918   precision: 4.55%\n",
      "[769/1000]  loss: 2.9919   precision: 5.00%\n",
      "[770/1000]  loss: 2.9907   precision: 5.25%\n",
      "[771/1000]  loss: 2.9910   precision: 5.05%\n",
      "[772/1000]  loss: 2.9954   precision: 5.30%\n",
      "[773/1000]  loss: 2.9907   precision: 5.20%\n",
      "[774/1000]  loss: 2.9925   precision: 4.65%\n",
      "[775/1000]  loss: 2.9931   precision: 5.00%\n",
      "[776/1000]  loss: 2.9940   precision: 4.95%\n",
      "[777/1000]  loss: 2.9942   precision: 5.20%\n",
      "[778/1000]  loss: 2.9929   precision: 5.00%\n",
      "[779/1000]  loss: 2.9950   precision: 4.65%\n",
      "[780/1000]  loss: 2.9912   precision: 5.10%\n",
      "[781/1000]  loss: 2.9898   precision: 5.00%\n",
      "[782/1000]  loss: 2.9946   precision: 4.80%\n",
      "[783/1000]  loss: 2.9904   precision: 5.05%\n",
      "[784/1000]  loss: 2.9919   precision: 5.25%\n",
      "[785/1000]  loss: 2.9937   precision: 4.95%\n",
      "[786/1000]  loss: 2.9961   precision: 5.30%\n",
      "[787/1000]  loss: 2.9892   precision: 4.55%\n",
      "[788/1000]  loss: 2.9938   precision: 5.05%\n",
      "[789/1000]  loss: 2.9926   precision: 5.50%\n",
      "[790/1000]  loss: 2.9972   precision: 4.85%\n",
      "[791/1000]  loss: 2.9947   precision: 5.05%\n",
      "[792/1000]  loss: 2.9912   precision: 5.15%\n",
      "[793/1000]  loss: 2.9939   precision: 4.55%\n",
      "[794/1000]  loss: 2.9934   precision: 4.85%\n",
      "[795/1000]  loss: 2.9898   precision: 5.30%\n",
      "[796/1000]  loss: 2.9968   precision: 5.30%\n",
      "[797/1000]  loss: 2.9891   precision: 4.95%\n",
      "[798/1000]  loss: 2.9947   precision: 6.00%\n",
      "[799/1000]  loss: 2.9937   precision: 5.05%\n",
      "[800/1000]  loss: 2.9934   precision: 4.95%\n",
      "[801/1000]  loss: 2.9917   precision: 5.00%\n",
      "[802/1000]  loss: 2.9923   precision: 4.90%\n",
      "[803/1000]  loss: 2.9951   precision: 4.80%\n",
      "[804/1000]  loss: 2.9942   precision: 5.75%\n",
      "[805/1000]  loss: 2.9923   precision: 5.30%\n",
      "[806/1000]  loss: 2.9917   precision: 5.10%\n",
      "[807/1000]  loss: 2.9917   precision: 5.00%\n",
      "[808/1000]  loss: 2.9951   precision: 4.80%\n",
      "[809/1000]  loss: 2.9914   precision: 5.35%\n",
      "[810/1000]  loss: 2.9931   precision: 5.40%\n",
      "[811/1000]  loss: 2.9949   precision: 4.75%\n",
      "[812/1000]  loss: 2.9906   precision: 4.75%\n",
      "[813/1000]  loss: 2.9939   precision: 5.70%\n",
      "[814/1000]  loss: 2.9919   precision: 5.55%\n",
      "[815/1000]  loss: 2.9937   precision: 5.50%\n",
      "[816/1000]  loss: 2.9903   precision: 4.75%\n",
      "[817/1000]  loss: 2.9928   precision: 4.60%\n",
      "[818/1000]  loss: 2.9934   precision: 4.50%\n",
      "[819/1000]  loss: 2.9930   precision: 4.80%\n",
      "[820/1000]  loss: 2.9892   precision: 5.00%\n",
      "[821/1000]  loss: 2.9942   precision: 4.85%\n",
      "[822/1000]  loss: 2.9929   precision: 5.55%\n",
      "[823/1000]  loss: 2.9943   precision: 5.00%\n",
      "[824/1000]  loss: 2.9919   precision: 5.25%\n",
      "[825/1000]  loss: 2.9899   precision: 5.25%\n",
      "[826/1000]  loss: 2.9966   precision: 4.85%\n",
      "[827/1000]  loss: 2.9940   precision: 4.90%\n",
      "[828/1000]  loss: 2.9910   precision: 5.65%\n",
      "[829/1000]  loss: 2.9914   precision: 5.25%\n",
      "[830/1000]  loss: 2.9901   precision: 5.25%\n",
      "[831/1000]  loss: 2.9943   precision: 5.50%\n",
      "[832/1000]  loss: 2.9946   precision: 5.25%\n",
      "[833/1000]  loss: 2.9906   precision: 5.10%\n",
      "[834/1000]  loss: 2.9911   precision: 4.95%\n",
      "[835/1000]  loss: 2.9922   precision: 5.10%\n",
      "[836/1000]  loss: 2.9960   precision: 5.20%\n",
      "[837/1000]  loss: 2.9911   precision: 5.05%\n",
      "[838/1000]  loss: 2.9947   precision: 5.15%\n",
      "[839/1000]  loss: 2.9937   precision: 4.85%\n",
      "[840/1000]  loss: 2.9918   precision: 5.00%\n",
      "[841/1000]  loss: 2.9911   precision: 5.05%\n",
      "[842/1000]  loss: 2.9922   precision: 5.20%\n",
      "[843/1000]  loss: 2.9942   precision: 5.10%\n",
      "[844/1000]  loss: 2.9958   precision: 4.95%\n",
      "[845/1000]  loss: 2.9936   precision: 4.75%\n",
      "[846/1000]  loss: 2.9900   precision: 5.20%\n",
      "[847/1000]  loss: 2.9913   precision: 5.10%\n",
      "[848/1000]  loss: 2.9950   precision: 4.90%\n",
      "[849/1000]  loss: 2.9926   precision: 4.95%\n",
      "[850/1000]  loss: 2.9891   precision: 4.35%\n",
      "[851/1000]  loss: 2.9920   precision: 4.35%\n",
      "[852/1000]  loss: 2.9935   precision: 5.50%\n",
      "[853/1000]  loss: 2.9904   precision: 4.70%\n",
      "[854/1000]  loss: 2.9914   precision: 5.30%\n",
      "[855/1000]  loss: 2.9922   precision: 4.80%\n",
      "[856/1000]  loss: 2.9912   precision: 5.30%\n",
      "[857/1000]  loss: 2.9912   precision: 4.95%\n",
      "[858/1000]  loss: 2.9916   precision: 5.00%\n",
      "[859/1000]  loss: 2.9916   precision: 4.35%\n",
      "[860/1000]  loss: 2.9914   precision: 4.25%\n",
      "[861/1000]  loss: 2.9895   precision: 5.15%\n",
      "[862/1000]  loss: 2.9910   precision: 5.40%\n",
      "[863/1000]  loss: 2.9936   precision: 5.35%\n",
      "[864/1000]  loss: 2.9886   precision: 5.35%\n",
      "[865/1000]  loss: 2.9919   precision: 5.65%\n",
      "[866/1000]  loss: 2.9891   precision: 4.75%\n",
      "[867/1000]  loss: 2.9914   precision: 4.65%\n",
      "[868/1000]  loss: 2.9946   precision: 5.30%\n",
      "[869/1000]  loss: 2.9933   precision: 4.90%\n",
      "[870/1000]  loss: 2.9971   precision: 5.10%\n",
      "[871/1000]  loss: 2.9920   precision: 5.40%\n",
      "[872/1000]  loss: 2.9903   precision: 4.70%\n",
      "[873/1000]  loss: 2.9891   precision: 5.00%\n",
      "[874/1000]  loss: 2.9928   precision: 5.20%\n",
      "[875/1000]  loss: 2.9941   precision: 4.75%\n",
      "[876/1000]  loss: 2.9907   precision: 4.75%\n",
      "[877/1000]  loss: 2.9931   precision: 5.05%\n",
      "[878/1000]  loss: 2.9912   precision: 5.60%\n",
      "[879/1000]  loss: 2.9934   precision: 5.20%\n",
      "[880/1000]  loss: 2.9908   precision: 5.60%\n",
      "[881/1000]  loss: 2.9923   precision: 4.45%\n",
      "[882/1000]  loss: 2.9923   precision: 4.80%\n",
      "[883/1000]  loss: 2.9932   precision: 4.90%\n",
      "[884/1000]  loss: 2.9941   precision: 5.55%\n",
      "[885/1000]  loss: 2.9909   precision: 5.15%\n",
      "[886/1000]  loss: 2.9935   precision: 4.80%\n",
      "[887/1000]  loss: 2.9938   precision: 4.80%\n",
      "[888/1000]  loss: 2.9928   precision: 5.00%\n",
      "[889/1000]  loss: 2.9868   precision: 5.15%\n",
      "[890/1000]  loss: 2.9906   precision: 5.35%\n",
      "[891/1000]  loss: 2.9894   precision: 4.95%\n",
      "[892/1000]  loss: 2.9962   precision: 4.80%\n",
      "[893/1000]  loss: 2.9894   precision: 4.90%\n",
      "[894/1000]  loss: 2.9950   precision: 4.80%\n",
      "[895/1000]  loss: 2.9930   precision: 4.85%\n",
      "[896/1000]  loss: 2.9946   precision: 5.45%\n",
      "[897/1000]  loss: 2.9932   precision: 4.85%\n",
      "[898/1000]  loss: 2.9952   precision: 4.95%\n",
      "[899/1000]  loss: 2.9922   precision: 5.35%\n",
      "[900/1000]  loss: 2.9887   precision: 5.35%\n",
      "[901/1000]  loss: 2.9961   precision: 5.25%\n",
      "[902/1000]  loss: 2.9917   precision: 5.10%\n",
      "[903/1000]  loss: 2.9924   precision: 4.80%\n",
      "[904/1000]  loss: 2.9910   precision: 5.65%\n",
      "[905/1000]  loss: 2.9946   precision: 5.35%\n",
      "[906/1000]  loss: 2.9903   precision: 5.40%\n",
      "[907/1000]  loss: 2.9924   precision: 4.80%\n",
      "[908/1000]  loss: 2.9935   precision: 5.70%\n",
      "[909/1000]  loss: 2.9926   precision: 5.30%\n",
      "[910/1000]  loss: 2.9946   precision: 5.40%\n",
      "[911/1000]  loss: 2.9909   precision: 4.55%\n",
      "[912/1000]  loss: 2.9961   precision: 5.20%\n",
      "[913/1000]  loss: 2.9870   precision: 4.90%\n",
      "[914/1000]  loss: 2.9926   precision: 4.90%\n",
      "[915/1000]  loss: 2.9917   precision: 3.90%\n",
      "[916/1000]  loss: 2.9931   precision: 5.25%\n",
      "[917/1000]  loss: 2.9913   precision: 4.60%\n",
      "[918/1000]  loss: 2.9942   precision: 4.65%\n",
      "[919/1000]  loss: 2.9882   precision: 4.80%\n",
      "[920/1000]  loss: 2.9946   precision: 4.95%\n",
      "[921/1000]  loss: 2.9915   precision: 4.50%\n",
      "[922/1000]  loss: 2.9946   precision: 5.75%\n",
      "[923/1000]  loss: 2.9973   precision: 5.50%\n",
      "[924/1000]  loss: 2.9912   precision: 5.05%\n",
      "[925/1000]  loss: 2.9908   precision: 5.10%\n",
      "[926/1000]  loss: 2.9910   precision: 4.50%\n",
      "[927/1000]  loss: 2.9938   precision: 4.40%\n",
      "[928/1000]  loss: 2.9905   precision: 5.50%\n",
      "[929/1000]  loss: 2.9955   precision: 5.60%\n",
      "[930/1000]  loss: 2.9877   precision: 5.25%\n",
      "[931/1000]  loss: 2.9961   precision: 4.75%\n",
      "[932/1000]  loss: 2.9965   precision: 4.80%\n",
      "[933/1000]  loss: 2.9895   precision: 5.65%\n",
      "[934/1000]  loss: 2.9938   precision: 4.95%\n",
      "[935/1000]  loss: 2.9905   precision: 5.45%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[936/1000]  loss: 2.9926   precision: 5.05%\n",
      "[937/1000]  loss: 2.9938   precision: 4.85%\n",
      "[938/1000]  loss: 2.9895   precision: 4.45%\n",
      "[939/1000]  loss: 2.9930   precision: 5.35%\n",
      "[940/1000]  loss: 2.9901   precision: 5.80%\n",
      "[941/1000]  loss: 2.9918   precision: 4.50%\n",
      "[942/1000]  loss: 2.9910   precision: 5.70%\n",
      "[943/1000]  loss: 2.9903   precision: 5.80%\n",
      "[944/1000]  loss: 2.9925   precision: 5.10%\n",
      "[945/1000]  loss: 2.9936   precision: 4.70%\n",
      "[946/1000]  loss: 2.9944   precision: 5.05%\n",
      "[947/1000]  loss: 2.9920   precision: 5.30%\n",
      "[948/1000]  loss: 2.9941   precision: 4.20%\n",
      "[949/1000]  loss: 2.9926   precision: 5.35%\n",
      "[950/1000]  loss: 2.9934   precision: 5.90%\n",
      "[951/1000]  loss: 2.9920   precision: 5.20%\n",
      "[952/1000]  loss: 2.9963   precision: 5.30%\n",
      "[953/1000]  loss: 2.9919   precision: 5.25%\n",
      "[954/1000]  loss: 2.9921   precision: 4.80%\n",
      "[955/1000]  loss: 2.9919   precision: 4.90%\n",
      "[956/1000]  loss: 2.9929   precision: 4.75%\n",
      "[957/1000]  loss: 2.9941   precision: 5.05%\n",
      "[958/1000]  loss: 2.9925   precision: 4.65%\n",
      "[959/1000]  loss: 2.9901   precision: 5.30%\n",
      "[960/1000]  loss: 2.9940   precision: 5.60%\n",
      "[961/1000]  loss: 2.9926   precision: 4.60%\n",
      "[962/1000]  loss: 2.9889   precision: 5.15%\n",
      "[963/1000]  loss: 2.9946   precision: 4.60%\n",
      "[964/1000]  loss: 2.9902   precision: 4.45%\n",
      "[965/1000]  loss: 2.9941   precision: 5.20%\n",
      "[966/1000]  loss: 2.9931   precision: 4.50%\n",
      "[967/1000]  loss: 2.9933   precision: 5.30%\n",
      "[968/1000]  loss: 2.9913   precision: 4.55%\n",
      "[969/1000]  loss: 2.9922   precision: 5.10%\n",
      "[970/1000]  loss: 2.9938   precision: 4.75%\n",
      "[971/1000]  loss: 2.9929   precision: 4.85%\n",
      "[972/1000]  loss: 2.9925   precision: 5.10%\n",
      "[973/1000]  loss: 2.9931   precision: 5.35%\n",
      "[974/1000]  loss: 2.9937   precision: 4.60%\n",
      "[975/1000]  loss: 2.9893   precision: 4.60%\n",
      "[976/1000]  loss: 2.9904   precision: 5.35%\n",
      "[977/1000]  loss: 2.9944   precision: 5.05%\n",
      "[978/1000]  loss: 2.9903   precision: 4.50%\n",
      "[979/1000]  loss: 2.9955   precision: 4.70%\n",
      "[980/1000]  loss: 2.9886   precision: 4.85%\n",
      "[981/1000]  loss: 2.9939   precision: 5.40%\n",
      "[982/1000]  loss: 2.9926   precision: 5.55%\n",
      "[983/1000]  loss: 2.9899   precision: 4.55%\n",
      "[984/1000]  loss: 2.9889   precision: 5.10%\n",
      "[985/1000]  loss: 2.9973   precision: 5.15%\n",
      "[986/1000]  loss: 2.9905   precision: 4.80%\n",
      "[987/1000]  loss: 2.9965   precision: 5.30%\n",
      "[988/1000]  loss: 2.9931   precision: 4.75%\n",
      "[989/1000]  loss: 2.9946   precision: 5.15%\n",
      "[990/1000]  loss: 2.9923   precision: 5.00%\n",
      "[991/1000]  loss: 2.9913   precision: 5.25%\n",
      "[992/1000]  loss: 2.9920   precision: 4.30%\n",
      "[993/1000]  loss: 2.9906   precision: 5.00%\n",
      "[994/1000]  loss: 2.9932   precision: 5.00%\n",
      "[995/1000]  loss: 2.9971   precision: 5.25%\n",
      "[996/1000]  loss: 2.9930   precision: 4.65%\n",
      "[997/1000]  loss: 2.9883   precision: 5.50%\n",
      "[998/1000]  loss: 2.9886   precision: 4.70%\n",
      "[999/1000]  loss: 2.9923   precision: 5.20%\n",
      "[1000/1000]  loss: 2.9956   precision: 5.50%\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCH):\n",
    "    for i, (adjs, labels, features) in enumerate(trainloader):\n",
    "        features = features.type(torch.float).cuda()\n",
    "        adjs = adjs.type(torch.float).cuda()\n",
    "        labels = labels.type(torch.long).cuda()\n",
    "        \n",
    "        optim.zero_grad()\n",
    "        outputs = model(features, adjs)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        predicts = outputs.argmax(dim=2)\n",
    "        precision = accuracy_score(labels.flatten().cpu(), predicts.flatten().cpu())\n",
    "    print(\"[{:3d}/{:3d}]  loss: {:.4f}   precision: {:5.2%}\".format(epoch+1, EPOCH, loss, precision))\n",
    "\n",
    "#     if(epoch % TEST == TEST-1):\n",
    "#         model.eval()\n",
    "        \n",
    "#         outputs = model(features)\n",
    "#         loss = loss_fn(outputs, adjs)\n",
    "        \n",
    "#         mask = outputs.cpu() > 0.9\n",
    "#         predicts = torch.zeros(outputs.shape).masked_fill_(mask, 1.0)\n",
    "#         precision = 0.0\n",
    "#         for adj, predict in zip(adjs, predicts):\n",
    "#             precision += accuracy_score(adj.cpu(), predict) / adjs.shape[0]\n",
    "        \n",
    "#         print(\"=============================================\")\n",
    "#         print(\"[Testing]  loss: {:.4f}   precision: {:5.2%}\".format(loss, precision))\n",
    "#         print(\"=============================================\")\n",
    "        \n",
    "#         model.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
