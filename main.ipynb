{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import GCN\n",
    "import GAT\n",
    "import utils\n",
    "import torch.nn as nn\n",
    "from torch.optim import SGD, Adam\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "NCLASS = 7\n",
    "NITER = 1000\n",
    "NTEST = 100\n",
    "LR = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "adj, features, labels, idx_train, idx_val, idx_test = utils.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fe06b5fda90>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(adj[:len(idx_train), :len(idx_train)].cpu(), cmap ='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = GCN.GCN(features.shape[0], features.shape[1], 1024, NCLASS, 0.3, False).cuda()\n",
    "model = GAT.GAT(features.shape[1], 16, adj.shape[0], NCLASS, 0.3).cuda()\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optim = Adam(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1/1000]  loss: 1.9612   precision: 10.71%\n",
      "[  2/1000]  loss: 1.9578   precision: 10.71%\n",
      "[  3/1000]  loss: 1.9590   precision: 10.00%\n",
      "[  4/1000]  loss: 1.9542   precision: 10.00%\n",
      "[  5/1000]  loss: 1.9548   precision: 10.00%\n",
      "[  6/1000]  loss: 1.9523   precision: 9.29%\n",
      "[  7/1000]  loss: 1.9453   precision: 10.71%\n",
      "[  8/1000]  loss: 1.9475   precision: 10.00%\n",
      "[  9/1000]  loss: 1.9430   precision: 9.29%\n",
      "[ 10/1000]  loss: 1.9426   precision: 10.00%\n",
      "[ 11/1000]  loss: 1.9413   precision: 9.29%\n",
      "[ 12/1000]  loss: 1.9382   precision: 10.71%\n",
      "[ 13/1000]  loss: 1.9367   precision: 10.00%\n",
      "[ 14/1000]  loss: 1.9344   precision: 10.71%\n",
      "[ 15/1000]  loss: 1.9306   precision: 10.00%\n",
      "[ 16/1000]  loss: 1.9317   precision: 10.00%\n",
      "[ 17/1000]  loss: 1.9277   precision: 11.43%\n",
      "[ 18/1000]  loss: 1.9239   precision: 10.00%\n",
      "[ 19/1000]  loss: 1.9239   precision: 10.00%\n",
      "[ 20/1000]  loss: 1.9233   precision: 12.14%\n",
      "[ 21/1000]  loss: 1.9143   precision: 10.71%\n",
      "[ 22/1000]  loss: 1.9150   precision: 11.43%\n",
      "[ 23/1000]  loss: 1.9153   precision: 11.43%\n",
      "[ 24/1000]  loss: 1.9087   precision: 13.57%\n",
      "[ 25/1000]  loss: 1.9022   precision: 16.43%\n",
      "[ 26/1000]  loss: 1.9080   precision: 15.71%\n",
      "[ 27/1000]  loss: 1.9069   precision: 15.00%\n",
      "[ 28/1000]  loss: 1.9020   precision: 22.86%\n",
      "[ 29/1000]  loss: 1.8934   precision: 27.14%\n",
      "[ 30/1000]  loss: 1.8961   precision: 32.86%\n",
      "[ 31/1000]  loss: 1.8913   precision: 30.00%\n",
      "[ 32/1000]  loss: 1.8972   precision: 27.86%\n",
      "[ 33/1000]  loss: 1.8928   precision: 26.43%\n",
      "[ 34/1000]  loss: 1.8929   precision: 26.43%\n",
      "[ 35/1000]  loss: 1.8868   precision: 30.00%\n",
      "[ 36/1000]  loss: 1.8816   precision: 32.86%\n",
      "[ 37/1000]  loss: 1.8796   precision: 32.86%\n",
      "[ 38/1000]  loss: 1.8726   precision: 31.43%\n",
      "[ 39/1000]  loss: 1.8680   precision: 32.86%\n",
      "[ 40/1000]  loss: 1.8773   precision: 32.14%\n",
      "[ 41/1000]  loss: 1.8708   precision: 32.86%\n",
      "[ 42/1000]  loss: 1.8742   precision: 32.14%\n",
      "[ 43/1000]  loss: 1.8706   precision: 29.29%\n",
      "[ 44/1000]  loss: 1.8745   precision: 27.14%\n",
      "[ 45/1000]  loss: 1.8590   precision: 30.00%\n",
      "[ 46/1000]  loss: 1.8635   precision: 30.71%\n",
      "[ 47/1000]  loss: 1.8574   precision: 32.14%\n",
      "[ 48/1000]  loss: 1.8657   precision: 29.29%\n",
      "[ 49/1000]  loss: 1.8464   precision: 29.29%\n",
      "[ 50/1000]  loss: 1.8478   precision: 28.57%\n",
      "[ 51/1000]  loss: 1.8566   precision: 27.86%\n",
      "[ 52/1000]  loss: 1.8385   precision: 27.86%\n",
      "[ 53/1000]  loss: 1.8356   precision: 30.00%\n",
      "[ 54/1000]  loss: 1.8301   precision: 30.71%\n",
      "[ 55/1000]  loss: 1.8368   precision: 30.00%\n",
      "[ 56/1000]  loss: 1.8325   precision: 30.00%\n",
      "[ 57/1000]  loss: 1.8250   precision: 31.43%\n",
      "[ 58/1000]  loss: 1.8431   precision: 27.86%\n",
      "[ 59/1000]  loss: 1.8298   precision: 30.00%\n",
      "[ 60/1000]  loss: 1.8294   precision: 29.29%\n",
      "[ 61/1000]  loss: 1.8363   precision: 29.29%\n",
      "[ 62/1000]  loss: 1.8264   precision: 32.14%\n",
      "[ 63/1000]  loss: 1.8329   precision: 30.71%\n",
      "[ 64/1000]  loss: 1.8047   precision: 30.71%\n",
      "[ 65/1000]  loss: 1.8034   precision: 30.00%\n",
      "[ 66/1000]  loss: 1.8060   precision: 28.57%\n",
      "[ 67/1000]  loss: 1.8071   precision: 29.29%\n",
      "[ 68/1000]  loss: 1.8093   precision: 28.57%\n",
      "[ 69/1000]  loss: 1.8039   precision: 31.43%\n",
      "[ 70/1000]  loss: 1.8062   precision: 32.86%\n",
      "[ 71/1000]  loss: 1.8031   precision: 31.43%\n",
      "[ 72/1000]  loss: 1.8018   precision: 30.00%\n",
      "[ 73/1000]  loss: 1.7977   precision: 31.43%\n",
      "[ 74/1000]  loss: 1.7952   precision: 30.71%\n",
      "[ 75/1000]  loss: 1.7938   precision: 33.57%\n",
      "[ 76/1000]  loss: 1.7948   precision: 29.29%\n",
      "[ 77/1000]  loss: 1.7788   precision: 27.86%\n",
      "[ 78/1000]  loss: 1.7824   precision: 32.14%\n",
      "[ 79/1000]  loss: 1.7866   precision: 28.57%\n",
      "[ 80/1000]  loss: 1.7860   precision: 31.43%\n",
      "[ 81/1000]  loss: 1.7742   precision: 32.86%\n",
      "[ 82/1000]  loss: 1.7871   precision: 29.29%\n",
      "[ 83/1000]  loss: 1.7717   precision: 31.43%\n",
      "[ 84/1000]  loss: 1.7757   precision: 30.00%\n",
      "[ 85/1000]  loss: 1.7778   precision: 28.57%\n",
      "[ 86/1000]  loss: 1.7839   precision: 32.86%\n",
      "[ 87/1000]  loss: 1.7552   precision: 31.43%\n",
      "[ 88/1000]  loss: 1.7545   precision: 32.14%\n",
      "[ 89/1000]  loss: 1.7664   precision: 28.57%\n",
      "[ 90/1000]  loss: 1.7513   precision: 29.29%\n",
      "[ 91/1000]  loss: 1.7279   precision: 33.57%\n",
      "[ 92/1000]  loss: 1.7387   precision: 34.29%\n",
      "[ 93/1000]  loss: 1.7390   precision: 32.86%\n",
      "[ 94/1000]  loss: 1.7601   precision: 33.57%\n",
      "[ 95/1000]  loss: 1.7533   precision: 32.86%\n",
      "[ 96/1000]  loss: 1.7299   precision: 35.00%\n",
      "[ 97/1000]  loss: 1.7265   precision: 32.86%\n",
      "[ 98/1000]  loss: 1.7545   precision: 34.29%\n",
      "[ 99/1000]  loss: 1.7279   precision: 34.29%\n",
      "[100/1000]  loss: 1.7338   precision: 37.14%\n",
      "=============================================\n",
      "[Testing]  loss: 1.8113   precision: 31.40%\n",
      "=============================================\n",
      "[101/1000]  loss: 1.7316   precision: 33.57%\n",
      "[102/1000]  loss: 1.7503   precision: 39.29%\n",
      "[103/1000]  loss: 1.7369   precision: 36.43%\n",
      "[104/1000]  loss: 1.7475   precision: 35.71%\n",
      "[105/1000]  loss: 1.7282   precision: 35.71%\n",
      "[106/1000]  loss: 1.7143   precision: 33.57%\n",
      "[107/1000]  loss: 1.7152   precision: 37.14%\n",
      "[108/1000]  loss: 1.7309   precision: 31.43%\n",
      "[109/1000]  loss: 1.7358   precision: 33.57%\n",
      "[110/1000]  loss: 1.7190   precision: 34.29%\n",
      "[111/1000]  loss: 1.7299   precision: 32.86%\n",
      "[112/1000]  loss: 1.7211   precision: 32.14%\n",
      "[113/1000]  loss: 1.7335   precision: 31.43%\n",
      "[114/1000]  loss: 1.7038   precision: 35.71%\n",
      "[115/1000]  loss: 1.6935   precision: 37.86%\n",
      "[116/1000]  loss: 1.7045   precision: 35.71%\n",
      "[117/1000]  loss: 1.6946   precision: 40.71%\n",
      "[118/1000]  loss: 1.7031   precision: 40.71%\n",
      "[119/1000]  loss: 1.6756   precision: 33.57%\n",
      "[120/1000]  loss: 1.6970   precision: 34.29%\n",
      "[121/1000]  loss: 1.6918   precision: 39.29%\n",
      "[122/1000]  loss: 1.6782   precision: 40.71%\n",
      "[123/1000]  loss: 1.6784   precision: 39.29%\n",
      "[124/1000]  loss: 1.6767   precision: 37.14%\n",
      "[125/1000]  loss: 1.6788   precision: 42.14%\n",
      "[126/1000]  loss: 1.6918   precision: 37.86%\n",
      "[127/1000]  loss: 1.6805   precision: 37.14%\n",
      "[128/1000]  loss: 1.6711   precision: 40.00%\n",
      "[129/1000]  loss: 1.6803   precision: 37.86%\n",
      "[130/1000]  loss: 1.6678   precision: 38.57%\n",
      "[131/1000]  loss: 1.6791   precision: 42.86%\n",
      "[132/1000]  loss: 1.6686   precision: 36.43%\n",
      "[133/1000]  loss: 1.6403   precision: 39.29%\n",
      "[134/1000]  loss: 1.6479   precision: 40.00%\n",
      "[135/1000]  loss: 1.6845   precision: 42.14%\n",
      "[136/1000]  loss: 1.6693   precision: 42.86%\n",
      "[137/1000]  loss: 1.6239   precision: 42.14%\n",
      "[138/1000]  loss: 1.6433   precision: 41.43%\n",
      "[139/1000]  loss: 1.6472   precision: 43.57%\n",
      "[140/1000]  loss: 1.6377   precision: 41.43%\n",
      "[141/1000]  loss: 1.6264   precision: 46.43%\n",
      "[142/1000]  loss: 1.6336   precision: 45.00%\n",
      "[143/1000]  loss: 1.6147   precision: 40.71%\n",
      "[144/1000]  loss: 1.6477   precision: 43.57%\n",
      "[145/1000]  loss: 1.6401   precision: 42.14%\n",
      "[146/1000]  loss: 1.6170   precision: 44.29%\n",
      "[147/1000]  loss: 1.6026   precision: 44.29%\n",
      "[148/1000]  loss: 1.6208   precision: 46.43%\n",
      "[149/1000]  loss: 1.6522   precision: 43.57%\n",
      "[150/1000]  loss: 1.6357   precision: 41.43%\n",
      "[151/1000]  loss: 1.6360   precision: 45.00%\n",
      "[152/1000]  loss: 1.6238   precision: 45.00%\n",
      "[153/1000]  loss: 1.6159   precision: 43.57%\n",
      "[154/1000]  loss: 1.6201   precision: 44.29%\n",
      "[155/1000]  loss: 1.6220   precision: 44.29%\n",
      "[156/1000]  loss: 1.5904   precision: 47.14%\n",
      "[157/1000]  loss: 1.5901   precision: 47.14%\n",
      "[158/1000]  loss: 1.6026   precision: 45.71%\n",
      "[159/1000]  loss: 1.6071   precision: 46.43%\n",
      "[160/1000]  loss: 1.5751   precision: 47.14%\n",
      "[161/1000]  loss: 1.5845   precision: 46.43%\n",
      "[162/1000]  loss: 1.6117   precision: 47.14%\n",
      "[163/1000]  loss: 1.5833   precision: 49.29%\n",
      "[164/1000]  loss: 1.6365   precision: 47.86%\n",
      "[165/1000]  loss: 1.5926   precision: 48.57%\n",
      "[166/1000]  loss: 1.5711   precision: 47.86%\n",
      "[167/1000]  loss: 1.5913   precision: 49.29%\n",
      "[168/1000]  loss: 1.5748   precision: 50.00%\n",
      "[169/1000]  loss: 1.5597   precision: 47.86%\n",
      "[170/1000]  loss: 1.5767   precision: 52.14%\n",
      "[171/1000]  loss: 1.5601   precision: 47.86%\n",
      "[172/1000]  loss: 1.5824   precision: 49.29%\n",
      "[173/1000]  loss: 1.5721   precision: 47.86%\n",
      "[174/1000]  loss: 1.5740   precision: 53.57%\n",
      "[175/1000]  loss: 1.5748   precision: 52.14%\n",
      "[176/1000]  loss: 1.5371   precision: 51.43%\n",
      "[177/1000]  loss: 1.5503   precision: 52.86%\n",
      "[178/1000]  loss: 1.5404   precision: 53.57%\n",
      "[179/1000]  loss: 1.5426   precision: 54.29%\n",
      "[180/1000]  loss: 1.5362   precision: 50.71%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[181/1000]  loss: 1.5288   precision: 57.14%\n",
      "[182/1000]  loss: 1.5521   precision: 54.29%\n",
      "[183/1000]  loss: 1.5418   precision: 55.71%\n",
      "[184/1000]  loss: 1.5390   precision: 55.71%\n",
      "[185/1000]  loss: 1.5221   precision: 52.14%\n",
      "[186/1000]  loss: 1.4805   precision: 52.14%\n",
      "[187/1000]  loss: 1.5700   precision: 57.14%\n",
      "[188/1000]  loss: 1.5622   precision: 51.43%\n",
      "[189/1000]  loss: 1.5477   precision: 51.43%\n",
      "[190/1000]  loss: 1.5248   precision: 55.00%\n",
      "[191/1000]  loss: 1.5248   precision: 55.00%\n",
      "[192/1000]  loss: 1.4825   precision: 57.14%\n",
      "[193/1000]  loss: 1.5262   precision: 57.14%\n",
      "[194/1000]  loss: 1.4871   precision: 56.43%\n",
      "[195/1000]  loss: 1.5008   precision: 57.86%\n",
      "[196/1000]  loss: 1.4798   precision: 56.43%\n",
      "[197/1000]  loss: 1.4999   precision: 55.71%\n",
      "[198/1000]  loss: 1.4983   precision: 58.57%\n",
      "[199/1000]  loss: 1.4724   precision: 58.57%\n",
      "[200/1000]  loss: 1.5043   precision: 58.57%\n",
      "=============================================\n",
      "[Testing]  loss: 1.6722   precision: 40.60%\n",
      "=============================================\n",
      "[201/1000]  loss: 1.4888   precision: 59.29%\n",
      "[202/1000]  loss: 1.4874   precision: 59.29%\n",
      "[203/1000]  loss: 1.5002   precision: 57.86%\n",
      "[204/1000]  loss: 1.4886   precision: 56.43%\n",
      "[205/1000]  loss: 1.4971   precision: 56.43%\n",
      "[206/1000]  loss: 1.4469   precision: 60.00%\n",
      "[207/1000]  loss: 1.4701   precision: 60.00%\n",
      "[208/1000]  loss: 1.5107   precision: 57.86%\n",
      "[209/1000]  loss: 1.4693   precision: 58.57%\n",
      "[210/1000]  loss: 1.4530   precision: 59.29%\n",
      "[211/1000]  loss: 1.4835   precision: 55.00%\n",
      "[212/1000]  loss: 1.4698   precision: 60.00%\n",
      "[213/1000]  loss: 1.4155   precision: 58.57%\n",
      "[214/1000]  loss: 1.4220   precision: 61.43%\n",
      "[215/1000]  loss: 1.4527   precision: 59.29%\n",
      "[216/1000]  loss: 1.4276   precision: 60.71%\n",
      "[217/1000]  loss: 1.4282   precision: 60.71%\n",
      "[218/1000]  loss: 1.4494   precision: 62.14%\n",
      "[219/1000]  loss: 1.4462   precision: 64.29%\n",
      "[220/1000]  loss: 1.4443   precision: 62.86%\n",
      "[221/1000]  loss: 1.4602   precision: 58.57%\n",
      "[222/1000]  loss: 1.4603   precision: 61.43%\n",
      "[223/1000]  loss: 1.4404   precision: 61.43%\n",
      "[224/1000]  loss: 1.4425   precision: 62.14%\n",
      "[225/1000]  loss: 1.4293   precision: 61.43%\n",
      "[226/1000]  loss: 1.4357   precision: 62.86%\n",
      "[227/1000]  loss: 1.4081   precision: 65.71%\n",
      "[228/1000]  loss: 1.4248   precision: 65.00%\n",
      "[229/1000]  loss: 1.3986   precision: 64.29%\n",
      "[230/1000]  loss: 1.4087   precision: 62.86%\n",
      "[231/1000]  loss: 1.4004   precision: 65.71%\n",
      "[232/1000]  loss: 1.3869   precision: 65.00%\n",
      "[233/1000]  loss: 1.3856   precision: 64.29%\n",
      "[234/1000]  loss: 1.3939   precision: 65.71%\n",
      "[235/1000]  loss: 1.4198   precision: 65.00%\n",
      "[236/1000]  loss: 1.4113   precision: 64.29%\n",
      "[237/1000]  loss: 1.3551   precision: 66.43%\n",
      "[238/1000]  loss: 1.3880   precision: 66.43%\n",
      "[239/1000]  loss: 1.3221   precision: 67.14%\n",
      "[240/1000]  loss: 1.3566   precision: 66.43%\n",
      "[241/1000]  loss: 1.3864   precision: 67.14%\n",
      "[242/1000]  loss: 1.3524   precision: 69.29%\n",
      "[243/1000]  loss: 1.3379   precision: 68.57%\n",
      "[244/1000]  loss: 1.3773   precision: 65.71%\n",
      "[245/1000]  loss: 1.3018   precision: 67.14%\n",
      "[246/1000]  loss: 1.3739   precision: 67.86%\n",
      "[247/1000]  loss: 1.3681   precision: 66.43%\n",
      "[248/1000]  loss: 1.3456   precision: 66.43%\n",
      "[249/1000]  loss: 1.3357   precision: 67.86%\n",
      "[250/1000]  loss: 1.3541   precision: 68.57%\n",
      "[251/1000]  loss: 1.3491   precision: 70.00%\n",
      "[252/1000]  loss: 1.3546   precision: 67.14%\n",
      "[253/1000]  loss: 1.3548   precision: 67.86%\n",
      "[254/1000]  loss: 1.3770   precision: 67.86%\n",
      "[255/1000]  loss: 1.2818   precision: 74.29%\n",
      "[256/1000]  loss: 1.3902   precision: 67.14%\n",
      "[257/1000]  loss: 1.2667   precision: 73.57%\n",
      "[258/1000]  loss: 1.3718   precision: 67.86%\n",
      "[259/1000]  loss: 1.2920   precision: 72.14%\n",
      "[260/1000]  loss: 1.2937   precision: 72.14%\n",
      "[261/1000]  loss: 1.3166   precision: 68.57%\n",
      "[262/1000]  loss: 1.3233   precision: 70.00%\n",
      "[263/1000]  loss: 1.2969   precision: 71.43%\n",
      "[264/1000]  loss: 1.2843   precision: 71.43%\n",
      "[265/1000]  loss: 1.2783   precision: 67.86%\n",
      "[266/1000]  loss: 1.3028   precision: 70.71%\n",
      "[267/1000]  loss: 1.2784   precision: 70.71%\n",
      "[268/1000]  loss: 1.3094   precision: 71.43%\n",
      "[269/1000]  loss: 1.2620   precision: 70.71%\n",
      "[270/1000]  loss: 1.2976   precision: 70.71%\n",
      "[271/1000]  loss: 1.2515   precision: 73.57%\n",
      "[272/1000]  loss: 1.2738   precision: 75.00%\n",
      "[273/1000]  loss: 1.2765   precision: 69.29%\n",
      "[274/1000]  loss: 1.2658   precision: 73.57%\n",
      "[275/1000]  loss: 1.2833   precision: 71.43%\n",
      "[276/1000]  loss: 1.2529   precision: 72.86%\n",
      "[277/1000]  loss: 1.2999   precision: 76.43%\n",
      "[278/1000]  loss: 1.2668   precision: 69.29%\n",
      "[279/1000]  loss: 1.2492   precision: 74.29%\n",
      "[280/1000]  loss: 1.2776   precision: 74.29%\n",
      "[281/1000]  loss: 1.2657   precision: 72.14%\n",
      "[282/1000]  loss: 1.2466   precision: 72.14%\n",
      "[283/1000]  loss: 1.2608   precision: 74.29%\n",
      "[284/1000]  loss: 1.2588   precision: 72.86%\n",
      "[285/1000]  loss: 1.2566   precision: 70.00%\n",
      "[286/1000]  loss: 1.2762   precision: 70.00%\n",
      "[287/1000]  loss: 1.2456   precision: 74.29%\n",
      "[288/1000]  loss: 1.2434   precision: 70.00%\n",
      "[289/1000]  loss: 1.2472   precision: 75.00%\n",
      "[290/1000]  loss: 1.2171   precision: 74.29%\n",
      "[291/1000]  loss: 1.2525   precision: 75.00%\n",
      "[292/1000]  loss: 1.2186   precision: 74.29%\n",
      "[293/1000]  loss: 1.2202   precision: 73.57%\n",
      "[294/1000]  loss: 1.2493   precision: 72.86%\n",
      "[295/1000]  loss: 1.2589   precision: 73.57%\n",
      "[296/1000]  loss: 1.2513   precision: 74.29%\n",
      "[297/1000]  loss: 1.1517   precision: 76.43%\n",
      "[298/1000]  loss: 1.2183   precision: 77.14%\n",
      "[299/1000]  loss: 1.2237   precision: 78.57%\n",
      "[300/1000]  loss: 1.2466   precision: 77.14%\n",
      "=============================================\n",
      "[Testing]  loss: 1.4753   precision: 57.00%\n",
      "=============================================\n",
      "[301/1000]  loss: 1.2240   precision: 77.14%\n",
      "[302/1000]  loss: 1.1882   precision: 76.43%\n",
      "[303/1000]  loss: 1.2116   precision: 76.43%\n",
      "[304/1000]  loss: 1.1352   precision: 80.71%\n",
      "[305/1000]  loss: 1.1687   precision: 76.43%\n",
      "[306/1000]  loss: 1.1740   precision: 76.43%\n",
      "[307/1000]  loss: 1.2044   precision: 75.71%\n",
      "[308/1000]  loss: 1.1997   precision: 78.57%\n",
      "[309/1000]  loss: 1.1163   precision: 75.71%\n",
      "[310/1000]  loss: 1.1956   precision: 77.86%\n",
      "[311/1000]  loss: 1.2150   precision: 77.14%\n",
      "[312/1000]  loss: 1.1151   precision: 79.29%\n",
      "[313/1000]  loss: 1.1373   precision: 76.43%\n",
      "[314/1000]  loss: 1.1271   precision: 78.57%\n",
      "[315/1000]  loss: 1.1620   precision: 75.00%\n",
      "[316/1000]  loss: 1.1570   precision: 78.57%\n",
      "[317/1000]  loss: 1.1440   precision: 82.14%\n",
      "[318/1000]  loss: 1.1144   precision: 78.57%\n",
      "[319/1000]  loss: 1.1885   precision: 77.86%\n",
      "[320/1000]  loss: 1.1444   precision: 77.86%\n",
      "[321/1000]  loss: 1.1613   precision: 80.00%\n",
      "[322/1000]  loss: 1.1177   precision: 80.71%\n",
      "[323/1000]  loss: 1.1552   precision: 79.29%\n",
      "[324/1000]  loss: 1.1509   precision: 77.14%\n",
      "[325/1000]  loss: 1.1059   precision: 82.14%\n",
      "[326/1000]  loss: 1.1429   precision: 79.29%\n",
      "[327/1000]  loss: 1.1941   precision: 79.29%\n",
      "[328/1000]  loss: 1.1121   precision: 80.00%\n",
      "[329/1000]  loss: 1.1386   precision: 78.57%\n",
      "[330/1000]  loss: 1.1068   precision: 77.86%\n",
      "[331/1000]  loss: 1.1047   precision: 77.86%\n",
      "[332/1000]  loss: 1.1885   precision: 80.00%\n",
      "[333/1000]  loss: 1.1336   precision: 80.71%\n",
      "[334/1000]  loss: 1.1154   precision: 79.29%\n",
      "[335/1000]  loss: 1.0801   precision: 82.14%\n",
      "[336/1000]  loss: 1.1220   precision: 80.00%\n",
      "[337/1000]  loss: 1.1352   precision: 80.00%\n",
      "[338/1000]  loss: 1.1153   precision: 78.57%\n",
      "[339/1000]  loss: 1.0805   precision: 82.14%\n",
      "[340/1000]  loss: 1.0920   precision: 82.14%\n",
      "[341/1000]  loss: 1.0824   precision: 78.57%\n",
      "[342/1000]  loss: 1.1206   precision: 77.86%\n",
      "[343/1000]  loss: 1.0985   precision: 80.71%\n",
      "[344/1000]  loss: 1.1223   precision: 80.00%\n",
      "[345/1000]  loss: 1.0605   precision: 82.86%\n",
      "[346/1000]  loss: 1.0609   precision: 78.57%\n",
      "[347/1000]  loss: 1.1254   precision: 80.71%\n",
      "[348/1000]  loss: 1.0219   precision: 82.86%\n",
      "[349/1000]  loss: 1.0380   precision: 82.14%\n",
      "[350/1000]  loss: 1.0895   precision: 82.86%\n",
      "[351/1000]  loss: 1.0952   precision: 81.43%\n",
      "[352/1000]  loss: 1.0703   precision: 80.71%\n",
      "[353/1000]  loss: 1.0570   precision: 85.71%\n",
      "[354/1000]  loss: 1.0466   precision: 84.29%\n",
      "[355/1000]  loss: 1.0586   precision: 84.29%\n",
      "[356/1000]  loss: 1.0748   precision: 82.86%\n",
      "[357/1000]  loss: 1.0384   precision: 84.29%\n",
      "[358/1000]  loss: 1.0205   precision: 81.43%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[359/1000]  loss: 1.0239   precision: 85.00%\n",
      "[360/1000]  loss: 0.9973   precision: 84.29%\n",
      "[361/1000]  loss: 1.0364   precision: 83.57%\n",
      "[362/1000]  loss: 0.9635   precision: 82.86%\n",
      "[363/1000]  loss: 1.0667   precision: 80.00%\n",
      "[364/1000]  loss: 1.0371   precision: 82.86%\n",
      "[365/1000]  loss: 1.0419   precision: 85.71%\n",
      "[366/1000]  loss: 1.0301   precision: 84.29%\n",
      "[367/1000]  loss: 1.0250   precision: 83.57%\n",
      "[368/1000]  loss: 1.0208   precision: 83.57%\n",
      "[369/1000]  loss: 1.0486   precision: 85.71%\n",
      "[370/1000]  loss: 1.0177   precision: 85.71%\n",
      "[371/1000]  loss: 1.0111   precision: 85.00%\n",
      "[372/1000]  loss: 0.9927   precision: 85.71%\n",
      "[373/1000]  loss: 0.9889   precision: 84.29%\n",
      "[374/1000]  loss: 0.9581   precision: 86.43%\n",
      "[375/1000]  loss: 1.0012   precision: 86.43%\n",
      "[376/1000]  loss: 1.0267   precision: 85.00%\n",
      "[377/1000]  loss: 0.9694   precision: 86.43%\n",
      "[378/1000]  loss: 0.9619   precision: 86.43%\n",
      "[379/1000]  loss: 1.0053   precision: 85.71%\n",
      "[380/1000]  loss: 0.9816   precision: 86.43%\n",
      "[381/1000]  loss: 0.9825   precision: 85.00%\n",
      "[382/1000]  loss: 0.9965   precision: 85.71%\n",
      "[383/1000]  loss: 1.0043   precision: 84.29%\n",
      "[384/1000]  loss: 1.0222   precision: 83.57%\n",
      "[385/1000]  loss: 0.9852   precision: 87.14%\n",
      "[386/1000]  loss: 1.0012   precision: 86.43%\n",
      "[387/1000]  loss: 0.9567   precision: 84.29%\n",
      "[388/1000]  loss: 0.9711   precision: 87.86%\n",
      "[389/1000]  loss: 1.0230   precision: 86.43%\n",
      "[390/1000]  loss: 0.9535   precision: 89.29%\n",
      "[391/1000]  loss: 1.0099   precision: 84.29%\n",
      "[392/1000]  loss: 0.9828   precision: 84.29%\n",
      "[393/1000]  loss: 0.9186   precision: 85.71%\n",
      "[394/1000]  loss: 0.9878   precision: 85.71%\n",
      "[395/1000]  loss: 0.9204   precision: 85.00%\n",
      "[396/1000]  loss: 0.9948   precision: 86.43%\n",
      "[397/1000]  loss: 0.8905   precision: 87.86%\n",
      "[398/1000]  loss: 0.9643   precision: 86.43%\n",
      "[399/1000]  loss: 0.9311   precision: 85.00%\n",
      "[400/1000]  loss: 0.9498   precision: 86.43%\n",
      "=============================================\n",
      "[Testing]  loss: 1.2756   precision: 72.10%\n",
      "=============================================\n",
      "[401/1000]  loss: 0.9694   precision: 85.00%\n",
      "[402/1000]  loss: 0.9458   precision: 87.86%\n",
      "[403/1000]  loss: 1.0006   precision: 86.43%\n",
      "[404/1000]  loss: 0.9150   precision: 87.86%\n",
      "[405/1000]  loss: 0.9543   precision: 88.57%\n",
      "[406/1000]  loss: 0.9341   precision: 87.14%\n",
      "[407/1000]  loss: 0.9169   precision: 84.29%\n",
      "[408/1000]  loss: 0.9516   precision: 89.29%\n",
      "[409/1000]  loss: 0.9397   precision: 85.00%\n",
      "[410/1000]  loss: 0.9493   precision: 83.57%\n",
      "[411/1000]  loss: 0.9462   precision: 85.00%\n",
      "[412/1000]  loss: 0.9460   precision: 87.14%\n",
      "[413/1000]  loss: 0.9838   precision: 85.71%\n",
      "[414/1000]  loss: 0.8786   precision: 86.43%\n",
      "[415/1000]  loss: 0.8972   precision: 88.57%\n",
      "[416/1000]  loss: 0.8795   precision: 85.71%\n",
      "[417/1000]  loss: 0.8824   precision: 88.57%\n",
      "[418/1000]  loss: 0.9700   precision: 85.71%\n",
      "[419/1000]  loss: 0.9087   precision: 89.29%\n",
      "[420/1000]  loss: 0.9060   precision: 90.71%\n",
      "[421/1000]  loss: 0.9134   precision: 85.00%\n",
      "[422/1000]  loss: 0.8865   precision: 88.57%\n",
      "[423/1000]  loss: 0.8910   precision: 85.71%\n",
      "[424/1000]  loss: 0.8876   precision: 85.71%\n",
      "[425/1000]  loss: 0.9834   precision: 89.29%\n",
      "[426/1000]  loss: 0.8373   precision: 89.29%\n",
      "[427/1000]  loss: 0.9059   precision: 84.29%\n",
      "[428/1000]  loss: 0.8824   precision: 86.43%\n",
      "[429/1000]  loss: 0.8831   precision: 87.14%\n",
      "[430/1000]  loss: 0.9175   precision: 86.43%\n",
      "[431/1000]  loss: 0.8324   precision: 90.00%\n",
      "[432/1000]  loss: 0.8732   precision: 87.86%\n",
      "[433/1000]  loss: 0.9476   precision: 87.14%\n",
      "[434/1000]  loss: 0.8759   precision: 87.14%\n",
      "[435/1000]  loss: 0.8774   precision: 88.57%\n",
      "[436/1000]  loss: 0.8884   precision: 87.86%\n",
      "[437/1000]  loss: 0.8570   precision: 87.14%\n",
      "[438/1000]  loss: 0.8485   precision: 88.57%\n",
      "[439/1000]  loss: 0.9578   precision: 86.43%\n",
      "[440/1000]  loss: 0.8664   precision: 89.29%\n",
      "[441/1000]  loss: 0.8058   precision: 90.00%\n",
      "[442/1000]  loss: 0.9035   precision: 85.71%\n",
      "[443/1000]  loss: 0.8663   precision: 86.43%\n",
      "[444/1000]  loss: 0.8443   precision: 88.57%\n",
      "[445/1000]  loss: 0.8781   precision: 88.57%\n",
      "[446/1000]  loss: 0.8783   precision: 87.14%\n",
      "[447/1000]  loss: 0.9004   precision: 89.29%\n",
      "[448/1000]  loss: 0.8848   precision: 85.71%\n",
      "[449/1000]  loss: 0.8079   precision: 89.29%\n",
      "[450/1000]  loss: 0.8087   precision: 87.14%\n",
      "[451/1000]  loss: 0.8847   precision: 85.00%\n",
      "[452/1000]  loss: 0.8286   precision: 87.86%\n",
      "[453/1000]  loss: 0.8037   precision: 88.57%\n",
      "[454/1000]  loss: 0.8019   precision: 89.29%\n",
      "[455/1000]  loss: 0.8315   precision: 89.29%\n",
      "[456/1000]  loss: 0.8558   precision: 86.43%\n",
      "[457/1000]  loss: 0.8149   precision: 87.86%\n",
      "[458/1000]  loss: 0.8341   precision: 86.43%\n",
      "[459/1000]  loss: 0.7986   precision: 89.29%\n",
      "[460/1000]  loss: 0.8551   precision: 85.71%\n",
      "[461/1000]  loss: 0.8426   precision: 87.14%\n",
      "[462/1000]  loss: 0.7968   precision: 91.43%\n",
      "[463/1000]  loss: 0.7923   precision: 90.71%\n",
      "[464/1000]  loss: 0.8150   precision: 90.00%\n",
      "[465/1000]  loss: 0.7819   precision: 88.57%\n",
      "[466/1000]  loss: 0.7470   precision: 91.43%\n",
      "[467/1000]  loss: 0.8018   precision: 90.00%\n",
      "[468/1000]  loss: 0.8462   precision: 88.57%\n",
      "[469/1000]  loss: 0.8162   precision: 90.00%\n",
      "[470/1000]  loss: 0.8174   precision: 88.57%\n",
      "[471/1000]  loss: 0.8233   precision: 90.00%\n",
      "[472/1000]  loss: 0.8364   precision: 90.00%\n",
      "[473/1000]  loss: 0.7950   precision: 87.14%\n",
      "[474/1000]  loss: 0.7432   precision: 92.86%\n",
      "[475/1000]  loss: 0.7669   precision: 87.86%\n",
      "[476/1000]  loss: 0.7604   precision: 89.29%\n",
      "[477/1000]  loss: 0.8162   precision: 89.29%\n",
      "[478/1000]  loss: 0.8178   precision: 90.71%\n",
      "[479/1000]  loss: 0.7604   precision: 88.57%\n",
      "[480/1000]  loss: 0.8106   precision: 87.86%\n",
      "[481/1000]  loss: 0.7824   precision: 89.29%\n",
      "[482/1000]  loss: 0.8244   precision: 85.71%\n",
      "[483/1000]  loss: 0.7728   precision: 88.57%\n",
      "[484/1000]  loss: 0.7752   precision: 89.29%\n",
      "[485/1000]  loss: 0.7268   precision: 88.57%\n",
      "[486/1000]  loss: 0.7577   precision: 88.57%\n",
      "[487/1000]  loss: 0.7831   precision: 89.29%\n",
      "[488/1000]  loss: 0.7648   precision: 86.43%\n",
      "[489/1000]  loss: 0.7928   precision: 88.57%\n",
      "[490/1000]  loss: 0.7739   precision: 90.00%\n",
      "[491/1000]  loss: 0.7080   precision: 93.57%\n",
      "[492/1000]  loss: 0.7814   precision: 89.29%\n",
      "[493/1000]  loss: 0.8147   precision: 87.14%\n",
      "[494/1000]  loss: 0.8017   precision: 85.71%\n",
      "[495/1000]  loss: 0.7232   precision: 90.00%\n",
      "[496/1000]  loss: 0.7589   precision: 87.86%\n",
      "[497/1000]  loss: 0.7648   precision: 86.43%\n",
      "[498/1000]  loss: 0.7325   precision: 88.57%\n",
      "[499/1000]  loss: 0.7442   precision: 89.29%\n",
      "[500/1000]  loss: 0.7706   precision: 84.29%\n",
      "=============================================\n",
      "[Testing]  loss: 1.1059   precision: 77.80%\n",
      "=============================================\n",
      "[501/1000]  loss: 0.6883   precision: 92.14%\n",
      "[502/1000]  loss: 0.7332   precision: 90.71%\n",
      "[503/1000]  loss: 0.7784   precision: 92.14%\n",
      "[504/1000]  loss: 0.7456   precision: 89.29%\n",
      "[505/1000]  loss: 0.8001   precision: 85.71%\n",
      "[506/1000]  loss: 0.7614   precision: 87.14%\n",
      "[507/1000]  loss: 0.7205   precision: 87.86%\n",
      "[508/1000]  loss: 0.7284   precision: 91.43%\n",
      "[509/1000]  loss: 0.6718   precision: 92.14%\n",
      "[510/1000]  loss: 0.7341   precision: 87.86%\n",
      "[511/1000]  loss: 0.8046   precision: 91.43%\n",
      "[512/1000]  loss: 0.7037   precision: 90.71%\n",
      "[513/1000]  loss: 0.7325   precision: 89.29%\n",
      "[514/1000]  loss: 0.7193   precision: 87.14%\n",
      "[515/1000]  loss: 0.7422   precision: 88.57%\n",
      "[516/1000]  loss: 0.7776   precision: 89.29%\n",
      "[517/1000]  loss: 0.7471   precision: 86.43%\n",
      "[518/1000]  loss: 0.7110   precision: 90.00%\n",
      "[519/1000]  loss: 0.6856   precision: 92.14%\n",
      "[520/1000]  loss: 0.7343   precision: 88.57%\n",
      "[521/1000]  loss: 0.6901   precision: 89.29%\n",
      "[522/1000]  loss: 0.6802   precision: 92.86%\n",
      "[523/1000]  loss: 0.7719   precision: 86.43%\n",
      "[524/1000]  loss: 0.6756   precision: 95.00%\n",
      "[525/1000]  loss: 0.6772   precision: 89.29%\n",
      "[526/1000]  loss: 0.7190   precision: 92.14%\n",
      "[527/1000]  loss: 0.6804   precision: 89.29%\n",
      "[528/1000]  loss: 0.6684   precision: 91.43%\n",
      "[529/1000]  loss: 0.6934   precision: 93.57%\n",
      "[530/1000]  loss: 0.6937   precision: 90.00%\n",
      "[531/1000]  loss: 0.6664   precision: 90.71%\n",
      "[532/1000]  loss: 0.6966   precision: 91.43%\n",
      "[533/1000]  loss: 0.6692   precision: 90.71%\n",
      "[534/1000]  loss: 0.7517   precision: 90.71%\n",
      "[535/1000]  loss: 0.6644   precision: 90.71%\n",
      "[536/1000]  loss: 0.6738   precision: 92.14%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[537/1000]  loss: 0.6199   precision: 90.71%\n",
      "[538/1000]  loss: 0.6603   precision: 90.71%\n",
      "[539/1000]  loss: 0.6166   precision: 92.14%\n",
      "[540/1000]  loss: 0.6434   precision: 90.71%\n",
      "[541/1000]  loss: 0.6253   precision: 92.14%\n",
      "[542/1000]  loss: 0.7137   precision: 89.29%\n",
      "[543/1000]  loss: 0.7169   precision: 90.00%\n",
      "[544/1000]  loss: 0.7169   precision: 92.86%\n",
      "[545/1000]  loss: 0.6654   precision: 93.57%\n",
      "[546/1000]  loss: 0.6811   precision: 89.29%\n",
      "[547/1000]  loss: 0.6606   precision: 91.43%\n",
      "[548/1000]  loss: 0.6545   precision: 90.00%\n",
      "[549/1000]  loss: 0.7345   precision: 90.00%\n",
      "[550/1000]  loss: 0.7235   precision: 90.00%\n",
      "[551/1000]  loss: 0.5895   precision: 91.43%\n",
      "[552/1000]  loss: 0.6616   precision: 90.71%\n",
      "[553/1000]  loss: 0.6513   precision: 90.71%\n",
      "[554/1000]  loss: 0.7191   precision: 85.00%\n",
      "[555/1000]  loss: 0.6858   precision: 89.29%\n",
      "[556/1000]  loss: 0.6351   precision: 91.43%\n",
      "[557/1000]  loss: 0.6477   precision: 92.86%\n",
      "[558/1000]  loss: 0.6468   precision: 90.71%\n",
      "[559/1000]  loss: 0.6420   precision: 88.57%\n",
      "[560/1000]  loss: 0.6792   precision: 90.71%\n",
      "[561/1000]  loss: 0.6198   precision: 89.29%\n",
      "[562/1000]  loss: 0.6289   precision: 92.14%\n",
      "[563/1000]  loss: 0.6589   precision: 92.14%\n",
      "[564/1000]  loss: 0.6377   precision: 89.29%\n",
      "[565/1000]  loss: 0.7233   precision: 88.57%\n",
      "[566/1000]  loss: 0.6320   precision: 90.71%\n",
      "[567/1000]  loss: 0.6902   precision: 88.57%\n",
      "[568/1000]  loss: 0.6488   precision: 94.29%\n",
      "[569/1000]  loss: 0.6064   precision: 90.00%\n",
      "[570/1000]  loss: 0.6368   precision: 89.29%\n",
      "[571/1000]  loss: 0.6938   precision: 85.71%\n",
      "[572/1000]  loss: 0.6150   precision: 91.43%\n",
      "[573/1000]  loss: 0.6641   precision: 92.14%\n",
      "[574/1000]  loss: 0.6410   precision: 92.14%\n",
      "[575/1000]  loss: 0.6599   precision: 88.57%\n",
      "[576/1000]  loss: 0.6393   precision: 93.57%\n",
      "[577/1000]  loss: 0.6338   precision: 87.14%\n",
      "[578/1000]  loss: 0.6158   precision: 91.43%\n",
      "[579/1000]  loss: 0.6342   precision: 92.86%\n",
      "[580/1000]  loss: 0.5588   precision: 92.86%\n",
      "[581/1000]  loss: 0.5988   precision: 92.14%\n",
      "[582/1000]  loss: 0.6572   precision: 90.00%\n",
      "[583/1000]  loss: 0.6335   precision: 88.57%\n",
      "[584/1000]  loss: 0.5566   precision: 94.29%\n",
      "[585/1000]  loss: 0.6386   precision: 91.43%\n",
      "[586/1000]  loss: 0.6791   precision: 93.57%\n",
      "[587/1000]  loss: 0.6541   precision: 92.14%\n",
      "[588/1000]  loss: 0.6114   precision: 92.14%\n",
      "[589/1000]  loss: 0.6294   precision: 92.14%\n",
      "[590/1000]  loss: 0.6062   precision: 92.14%\n",
      "[591/1000]  loss: 0.6009   precision: 90.71%\n",
      "[592/1000]  loss: 0.5864   precision: 92.86%\n",
      "[593/1000]  loss: 0.5975   precision: 92.86%\n",
      "[594/1000]  loss: 0.6246   precision: 92.14%\n",
      "[595/1000]  loss: 0.5958   precision: 91.43%\n",
      "[596/1000]  loss: 0.5478   precision: 92.14%\n",
      "[597/1000]  loss: 0.6000   precision: 95.00%\n",
      "[598/1000]  loss: 0.5805   precision: 92.86%\n",
      "[599/1000]  loss: 0.6019   precision: 91.43%\n",
      "[600/1000]  loss: 0.5858   precision: 92.14%\n",
      "=============================================\n",
      "[Testing]  loss: 0.9699   precision: 80.60%\n",
      "=============================================\n",
      "[601/1000]  loss: 0.5894   precision: 89.29%\n",
      "[602/1000]  loss: 0.5488   precision: 93.57%\n",
      "[603/1000]  loss: 0.6025   precision: 91.43%\n",
      "[604/1000]  loss: 0.6431   precision: 89.29%\n",
      "[605/1000]  loss: 0.5829   precision: 91.43%\n",
      "[606/1000]  loss: 0.5318   precision: 92.86%\n",
      "[607/1000]  loss: 0.5624   precision: 90.00%\n",
      "[608/1000]  loss: 0.6050   precision: 91.43%\n",
      "[609/1000]  loss: 0.6047   precision: 91.43%\n",
      "[610/1000]  loss: 0.5427   precision: 91.43%\n",
      "[611/1000]  loss: 0.5411   precision: 93.57%\n",
      "[612/1000]  loss: 0.5265   precision: 95.71%\n",
      "[613/1000]  loss: 0.6350   precision: 90.00%\n",
      "[614/1000]  loss: 0.6170   precision: 95.00%\n",
      "[615/1000]  loss: 0.5479   precision: 91.43%\n",
      "[616/1000]  loss: 0.5759   precision: 93.57%\n",
      "[617/1000]  loss: 0.5910   precision: 92.14%\n",
      "[618/1000]  loss: 0.5579   precision: 93.57%\n",
      "[619/1000]  loss: 0.4873   precision: 93.57%\n",
      "[620/1000]  loss: 0.6011   precision: 91.43%\n",
      "[621/1000]  loss: 0.6205   precision: 90.00%\n",
      "[622/1000]  loss: 0.5961   precision: 92.14%\n",
      "[623/1000]  loss: 0.5485   precision: 94.29%\n",
      "[624/1000]  loss: 0.5529   precision: 94.29%\n",
      "[625/1000]  loss: 0.5542   precision: 92.14%\n",
      "[626/1000]  loss: 0.5724   precision: 92.14%\n",
      "[627/1000]  loss: 0.6003   precision: 92.86%\n",
      "[628/1000]  loss: 0.5798   precision: 92.14%\n",
      "[629/1000]  loss: 0.5667   precision: 92.86%\n",
      "[630/1000]  loss: 0.5546   precision: 95.71%\n",
      "[631/1000]  loss: 0.5632   precision: 93.57%\n",
      "[632/1000]  loss: 0.6159   precision: 89.29%\n",
      "[633/1000]  loss: 0.5647   precision: 90.71%\n",
      "[634/1000]  loss: 0.5565   precision: 90.00%\n",
      "[635/1000]  loss: 0.6205   precision: 90.71%\n",
      "[636/1000]  loss: 0.5957   precision: 88.57%\n",
      "[637/1000]  loss: 0.5719   precision: 94.29%\n",
      "[638/1000]  loss: 0.5045   precision: 92.86%\n",
      "[639/1000]  loss: 0.5503   precision: 91.43%\n",
      "[640/1000]  loss: 0.5478   precision: 94.29%\n",
      "[641/1000]  loss: 0.5270   precision: 91.43%\n",
      "[642/1000]  loss: 0.6151   precision: 92.14%\n",
      "[643/1000]  loss: 0.5150   precision: 92.14%\n",
      "[644/1000]  loss: 0.4800   precision: 93.57%\n",
      "[645/1000]  loss: 0.4497   precision: 95.00%\n",
      "[646/1000]  loss: 0.5858   precision: 90.71%\n",
      "[647/1000]  loss: 0.5583   precision: 90.71%\n",
      "[648/1000]  loss: 0.4906   precision: 91.43%\n",
      "[649/1000]  loss: 0.5234   precision: 93.57%\n",
      "[650/1000]  loss: 0.5131   precision: 89.29%\n",
      "[651/1000]  loss: 0.4929   precision: 95.71%\n",
      "[652/1000]  loss: 0.5834   precision: 92.86%\n",
      "[653/1000]  loss: 0.5494   precision: 91.43%\n",
      "[654/1000]  loss: 0.5366   precision: 92.14%\n",
      "[655/1000]  loss: 0.4978   precision: 94.29%\n",
      "[656/1000]  loss: 0.5344   precision: 95.00%\n",
      "[657/1000]  loss: 0.5455   precision: 90.71%\n",
      "[658/1000]  loss: 0.4840   precision: 93.57%\n",
      "[659/1000]  loss: 0.5943   precision: 92.14%\n",
      "[660/1000]  loss: 0.5325   precision: 92.14%\n",
      "[661/1000]  loss: 0.5950   precision: 91.43%\n",
      "[662/1000]  loss: 0.5231   precision: 95.00%\n",
      "[663/1000]  loss: 0.5190   precision: 93.57%\n",
      "[664/1000]  loss: 0.5479   precision: 91.43%\n",
      "[665/1000]  loss: 0.5764   precision: 92.86%\n",
      "[666/1000]  loss: 0.5584   precision: 95.00%\n",
      "[667/1000]  loss: 0.5443   precision: 89.29%\n",
      "[668/1000]  loss: 0.5626   precision: 91.43%\n",
      "[669/1000]  loss: 0.5189   precision: 92.86%\n",
      "[670/1000]  loss: 0.5543   precision: 90.00%\n",
      "[671/1000]  loss: 0.4725   precision: 93.57%\n",
      "[672/1000]  loss: 0.5650   precision: 90.71%\n",
      "[673/1000]  loss: 0.5242   precision: 95.00%\n",
      "[674/1000]  loss: 0.4834   precision: 92.14%\n",
      "[675/1000]  loss: 0.5055   precision: 96.43%\n",
      "[676/1000]  loss: 0.5375   precision: 92.14%\n",
      "[677/1000]  loss: 0.5370   precision: 95.00%\n",
      "[678/1000]  loss: 0.5158   precision: 92.14%\n",
      "[679/1000]  loss: 0.5245   precision: 92.86%\n",
      "[680/1000]  loss: 0.4798   precision: 95.00%\n",
      "[681/1000]  loss: 0.5262   precision: 92.86%\n",
      "[682/1000]  loss: 0.5164   precision: 87.86%\n",
      "[683/1000]  loss: 0.5619   precision: 91.43%\n",
      "[684/1000]  loss: 0.4803   precision: 95.00%\n",
      "[685/1000]  loss: 0.5316   precision: 91.43%\n",
      "[686/1000]  loss: 0.5265   precision: 95.00%\n",
      "[687/1000]  loss: 0.5269   precision: 92.86%\n",
      "[688/1000]  loss: 0.5218   precision: 93.57%\n",
      "[689/1000]  loss: 0.4755   precision: 94.29%\n",
      "[690/1000]  loss: 0.5272   precision: 90.00%\n",
      "[691/1000]  loss: 0.5382   precision: 90.71%\n",
      "[692/1000]  loss: 0.5330   precision: 92.86%\n",
      "[693/1000]  loss: 0.4896   precision: 95.71%\n",
      "[694/1000]  loss: 0.4315   precision: 92.86%\n",
      "[695/1000]  loss: 0.4183   precision: 94.29%\n",
      "[696/1000]  loss: 0.5004   precision: 92.14%\n",
      "[697/1000]  loss: 0.5022   precision: 92.14%\n",
      "[698/1000]  loss: 0.5464   precision: 92.14%\n",
      "[699/1000]  loss: 0.5315   precision: 93.57%\n",
      "[700/1000]  loss: 0.5364   precision: 92.14%\n",
      "=============================================\n",
      "[Testing]  loss: 0.8726   precision: 80.50%\n",
      "=============================================\n",
      "[701/1000]  loss: 0.4505   precision: 94.29%\n",
      "[702/1000]  loss: 0.4969   precision: 93.57%\n",
      "[703/1000]  loss: 0.5188   precision: 90.71%\n",
      "[704/1000]  loss: 0.4225   precision: 94.29%\n",
      "[705/1000]  loss: 0.5252   precision: 93.57%\n",
      "[706/1000]  loss: 0.5197   precision: 94.29%\n",
      "[707/1000]  loss: 0.5032   precision: 92.14%\n",
      "[708/1000]  loss: 0.5260   precision: 93.57%\n",
      "[709/1000]  loss: 0.4861   precision: 93.57%\n",
      "[710/1000]  loss: 0.4779   precision: 91.43%\n",
      "[711/1000]  loss: 0.4874   precision: 92.86%\n",
      "[712/1000]  loss: 0.4556   precision: 90.71%\n",
      "[713/1000]  loss: 0.5513   precision: 92.14%\n",
      "[714/1000]  loss: 0.5097   precision: 92.86%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[715/1000]  loss: 0.5026   precision: 90.71%\n",
      "[716/1000]  loss: 0.4605   precision: 96.43%\n",
      "[717/1000]  loss: 0.5339   precision: 92.86%\n",
      "[718/1000]  loss: 0.4723   precision: 93.57%\n",
      "[719/1000]  loss: 0.5029   precision: 91.43%\n",
      "[720/1000]  loss: 0.4427   precision: 93.57%\n",
      "[721/1000]  loss: 0.4435   precision: 95.00%\n",
      "[722/1000]  loss: 0.4829   precision: 93.57%\n",
      "[723/1000]  loss: 0.4978   precision: 92.14%\n",
      "[724/1000]  loss: 0.3837   precision: 96.43%\n",
      "[725/1000]  loss: 0.4272   precision: 96.43%\n",
      "[726/1000]  loss: 0.5049   precision: 94.29%\n",
      "[727/1000]  loss: 0.5050   precision: 90.00%\n",
      "[728/1000]  loss: 0.4653   precision: 93.57%\n",
      "[729/1000]  loss: 0.4684   precision: 92.14%\n",
      "[730/1000]  loss: 0.5187   precision: 92.86%\n",
      "[731/1000]  loss: 0.4645   precision: 91.43%\n",
      "[732/1000]  loss: 0.4271   precision: 95.71%\n",
      "[733/1000]  loss: 0.4913   precision: 93.57%\n",
      "[734/1000]  loss: 0.4780   precision: 92.86%\n",
      "[735/1000]  loss: 0.4309   precision: 92.86%\n",
      "[736/1000]  loss: 0.4312   precision: 95.71%\n",
      "[737/1000]  loss: 0.4304   precision: 94.29%\n",
      "[738/1000]  loss: 0.4422   precision: 92.14%\n",
      "[739/1000]  loss: 0.5013   precision: 94.29%\n",
      "[740/1000]  loss: 0.4725   precision: 92.14%\n",
      "[741/1000]  loss: 0.4113   precision: 95.71%\n",
      "[742/1000]  loss: 0.4918   precision: 89.29%\n",
      "[743/1000]  loss: 0.4959   precision: 90.71%\n",
      "[744/1000]  loss: 0.4448   precision: 96.43%\n",
      "[745/1000]  loss: 0.4547   precision: 94.29%\n",
      "[746/1000]  loss: 0.4081   precision: 97.86%\n",
      "[747/1000]  loss: 0.3862   precision: 96.43%\n",
      "[748/1000]  loss: 0.3762   precision: 93.57%\n",
      "[749/1000]  loss: 0.4998   precision: 93.57%\n",
      "[750/1000]  loss: 0.4789   precision: 91.43%\n",
      "[751/1000]  loss: 0.4822   precision: 91.43%\n",
      "[752/1000]  loss: 0.4854   precision: 96.43%\n",
      "[753/1000]  loss: 0.4606   precision: 93.57%\n",
      "[754/1000]  loss: 0.4547   precision: 91.43%\n",
      "[755/1000]  loss: 0.5219   precision: 88.57%\n",
      "[756/1000]  loss: 0.4589   precision: 95.71%\n",
      "[757/1000]  loss: 0.4574   precision: 95.00%\n",
      "[758/1000]  loss: 0.4745   precision: 92.86%\n",
      "[759/1000]  loss: 0.4576   precision: 95.71%\n",
      "[760/1000]  loss: 0.4005   precision: 95.71%\n",
      "[761/1000]  loss: 0.4919   precision: 91.43%\n",
      "[762/1000]  loss: 0.4106   precision: 93.57%\n",
      "[763/1000]  loss: 0.4175   precision: 92.86%\n",
      "[764/1000]  loss: 0.4574   precision: 94.29%\n",
      "[765/1000]  loss: 0.4570   precision: 92.14%\n",
      "[766/1000]  loss: 0.3990   precision: 92.86%\n",
      "[767/1000]  loss: 0.4333   precision: 95.00%\n",
      "[768/1000]  loss: 0.4860   precision: 93.57%\n",
      "[769/1000]  loss: 0.4519   precision: 91.43%\n",
      "[770/1000]  loss: 0.4649   precision: 92.86%\n",
      "[771/1000]  loss: 0.4494   precision: 94.29%\n",
      "[772/1000]  loss: 0.4341   precision: 92.86%\n",
      "[773/1000]  loss: 0.4349   precision: 92.14%\n",
      "[774/1000]  loss: 0.4357   precision: 93.57%\n",
      "[775/1000]  loss: 0.3985   precision: 95.00%\n",
      "[776/1000]  loss: 0.4314   precision: 94.29%\n",
      "[777/1000]  loss: 0.4053   precision: 97.86%\n",
      "[778/1000]  loss: 0.3984   precision: 95.71%\n",
      "[779/1000]  loss: 0.4403   precision: 95.71%\n",
      "[780/1000]  loss: 0.4200   precision: 95.71%\n",
      "[781/1000]  loss: 0.4553   precision: 90.71%\n",
      "[782/1000]  loss: 0.3941   precision: 95.00%\n",
      "[783/1000]  loss: 0.4162   precision: 91.43%\n",
      "[784/1000]  loss: 0.4635   precision: 92.14%\n",
      "[785/1000]  loss: 0.4165   precision: 93.57%\n",
      "[786/1000]  loss: 0.4536   precision: 93.57%\n",
      "[787/1000]  loss: 0.3676   precision: 94.29%\n",
      "[788/1000]  loss: 0.3785   precision: 93.57%\n",
      "[789/1000]  loss: 0.4135   precision: 92.14%\n",
      "[790/1000]  loss: 0.3963   precision: 92.86%\n",
      "[791/1000]  loss: 0.4428   precision: 91.43%\n",
      "[792/1000]  loss: 0.4417   precision: 91.43%\n",
      "[793/1000]  loss: 0.4100   precision: 93.57%\n",
      "[794/1000]  loss: 0.3839   precision: 93.57%\n",
      "[795/1000]  loss: 0.4373   precision: 92.86%\n",
      "[796/1000]  loss: 0.4449   precision: 92.86%\n",
      "[797/1000]  loss: 0.4273   precision: 91.43%\n",
      "[798/1000]  loss: 0.3981   precision: 94.29%\n",
      "[799/1000]  loss: 0.3575   precision: 96.43%\n",
      "[800/1000]  loss: 0.4024   precision: 94.29%\n",
      "=============================================\n",
      "[Testing]  loss: 0.8013   precision: 79.90%\n",
      "=============================================\n",
      "[801/1000]  loss: 0.4421   precision: 95.00%\n",
      "[802/1000]  loss: 0.3859   precision: 95.00%\n",
      "[803/1000]  loss: 0.4375   precision: 93.57%\n",
      "[804/1000]  loss: 0.3688   precision: 94.29%\n",
      "[805/1000]  loss: 0.3694   precision: 95.71%\n",
      "[806/1000]  loss: 0.3839   precision: 95.00%\n",
      "[807/1000]  loss: 0.3840   precision: 97.14%\n",
      "[808/1000]  loss: 0.4729   precision: 92.14%\n",
      "[809/1000]  loss: 0.3830   precision: 95.71%\n",
      "[810/1000]  loss: 0.3648   precision: 97.14%\n",
      "[811/1000]  loss: 0.4177   precision: 94.29%\n",
      "[812/1000]  loss: 0.4365   precision: 95.71%\n",
      "[813/1000]  loss: 0.3877   precision: 93.57%\n",
      "[814/1000]  loss: 0.4369   precision: 94.29%\n",
      "[815/1000]  loss: 0.4497   precision: 90.71%\n",
      "[816/1000]  loss: 0.4185   precision: 94.29%\n",
      "[817/1000]  loss: 0.4387   precision: 92.14%\n",
      "[818/1000]  loss: 0.3315   precision: 95.71%\n",
      "[819/1000]  loss: 0.3584   precision: 96.43%\n",
      "[820/1000]  loss: 0.3831   precision: 95.00%\n",
      "[821/1000]  loss: 0.4119   precision: 92.86%\n",
      "[822/1000]  loss: 0.3142   precision: 95.71%\n",
      "[823/1000]  loss: 0.3683   precision: 95.71%\n",
      "[824/1000]  loss: 0.3928   precision: 95.71%\n",
      "[825/1000]  loss: 0.4047   precision: 93.57%\n",
      "[826/1000]  loss: 0.4235   precision: 93.57%\n",
      "[827/1000]  loss: 0.4404   precision: 92.86%\n",
      "[828/1000]  loss: 0.4033   precision: 95.00%\n",
      "[829/1000]  loss: 0.3759   precision: 96.43%\n",
      "[830/1000]  loss: 0.3807   precision: 95.00%\n",
      "[831/1000]  loss: 0.3987   precision: 92.86%\n",
      "[832/1000]  loss: 0.3452   precision: 95.71%\n",
      "[833/1000]  loss: 0.3717   precision: 95.00%\n",
      "[834/1000]  loss: 0.3154   precision: 97.14%\n",
      "[835/1000]  loss: 0.4219   precision: 92.14%\n",
      "[836/1000]  loss: 0.3976   precision: 94.29%\n",
      "[837/1000]  loss: 0.4281   precision: 93.57%\n",
      "[838/1000]  loss: 0.3239   precision: 96.43%\n",
      "[839/1000]  loss: 0.4089   precision: 95.00%\n",
      "[840/1000]  loss: 0.3693   precision: 94.29%\n",
      "[841/1000]  loss: 0.3673   precision: 97.14%\n",
      "[842/1000]  loss: 0.3788   precision: 95.00%\n",
      "[843/1000]  loss: 0.4249   precision: 95.00%\n",
      "[844/1000]  loss: 0.3706   precision: 97.14%\n",
      "[845/1000]  loss: 0.3686   precision: 96.43%\n",
      "[846/1000]  loss: 0.4173   precision: 97.14%\n",
      "[847/1000]  loss: 0.4565   precision: 92.14%\n",
      "[848/1000]  loss: 0.3788   precision: 93.57%\n",
      "[849/1000]  loss: 0.4206   precision: 90.71%\n",
      "[850/1000]  loss: 0.3952   precision: 97.14%\n",
      "[851/1000]  loss: 0.3932   precision: 95.00%\n",
      "[852/1000]  loss: 0.4429   precision: 91.43%\n",
      "[853/1000]  loss: 0.4045   precision: 93.57%\n",
      "[854/1000]  loss: 0.3465   precision: 97.14%\n",
      "[855/1000]  loss: 0.4217   precision: 95.00%\n",
      "[856/1000]  loss: 0.3957   precision: 93.57%\n",
      "[857/1000]  loss: 0.3981   precision: 93.57%\n",
      "[858/1000]  loss: 0.4510   precision: 91.43%\n",
      "[859/1000]  loss: 0.3593   precision: 95.71%\n",
      "[860/1000]  loss: 0.3100   precision: 95.00%\n",
      "[861/1000]  loss: 0.3547   precision: 93.57%\n",
      "[862/1000]  loss: 0.3659   precision: 95.71%\n",
      "[863/1000]  loss: 0.3841   precision: 94.29%\n",
      "[864/1000]  loss: 0.3412   precision: 96.43%\n",
      "[865/1000]  loss: 0.3356   precision: 97.86%\n",
      "[866/1000]  loss: 0.3121   precision: 97.14%\n",
      "[867/1000]  loss: 0.3947   precision: 97.14%\n",
      "[868/1000]  loss: 0.4139   precision: 93.57%\n",
      "[869/1000]  loss: 0.3634   precision: 96.43%\n",
      "[870/1000]  loss: 0.4184   precision: 92.86%\n",
      "[871/1000]  loss: 0.3845   precision: 94.29%\n",
      "[872/1000]  loss: 0.3420   precision: 95.71%\n",
      "[873/1000]  loss: 0.3312   precision: 97.14%\n",
      "[874/1000]  loss: 0.4005   precision: 94.29%\n",
      "[875/1000]  loss: 0.3500   precision: 95.00%\n",
      "[876/1000]  loss: 0.3655   precision: 94.29%\n",
      "[877/1000]  loss: 0.3960   precision: 92.86%\n",
      "[878/1000]  loss: 0.3467   precision: 96.43%\n",
      "[879/1000]  loss: 0.3036   precision: 97.14%\n",
      "[880/1000]  loss: 0.2785   precision: 95.71%\n",
      "[881/1000]  loss: 0.3103   precision: 95.71%\n",
      "[882/1000]  loss: 0.3282   precision: 96.43%\n",
      "[883/1000]  loss: 0.3119   precision: 95.71%\n",
      "[884/1000]  loss: 0.3473   precision: 95.00%\n",
      "[885/1000]  loss: 0.3628   precision: 94.29%\n",
      "[886/1000]  loss: 0.3605   precision: 95.00%\n",
      "[887/1000]  loss: 0.3840   precision: 94.29%\n",
      "[888/1000]  loss: 0.3228   precision: 95.00%\n",
      "[889/1000]  loss: 0.3688   precision: 91.43%\n",
      "[890/1000]  loss: 0.4517   precision: 91.43%\n",
      "[891/1000]  loss: 0.3821   precision: 92.86%\n",
      "[892/1000]  loss: 0.2911   precision: 98.57%\n",
      "[893/1000]  loss: 0.3980   precision: 93.57%\n",
      "[894/1000]  loss: 0.4265   precision: 90.71%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[895/1000]  loss: 0.3234   precision: 94.29%\n",
      "[896/1000]  loss: 0.3215   precision: 94.29%\n",
      "[897/1000]  loss: 0.4309   precision: 94.29%\n",
      "[898/1000]  loss: 0.3180   precision: 95.00%\n",
      "[899/1000]  loss: 0.3575   precision: 95.71%\n",
      "[900/1000]  loss: 0.3223   precision: 95.71%\n",
      "=============================================\n",
      "[Testing]  loss: 0.7458   precision: 79.90%\n",
      "=============================================\n",
      "[901/1000]  loss: 0.2981   precision: 98.57%\n",
      "[902/1000]  loss: 0.3113   precision: 94.29%\n",
      "[903/1000]  loss: 0.3356   precision: 95.71%\n",
      "[904/1000]  loss: 0.3703   precision: 92.86%\n",
      "[905/1000]  loss: 0.3989   precision: 92.14%\n",
      "[906/1000]  loss: 0.3897   precision: 90.71%\n",
      "[907/1000]  loss: 0.3158   precision: 94.29%\n",
      "[908/1000]  loss: 0.3575   precision: 92.14%\n",
      "[909/1000]  loss: 0.3566   precision: 95.71%\n",
      "[910/1000]  loss: 0.3789   precision: 95.00%\n",
      "[911/1000]  loss: 0.4248   precision: 92.14%\n",
      "[912/1000]  loss: 0.2799   precision: 96.43%\n",
      "[913/1000]  loss: 0.3439   precision: 95.71%\n",
      "[914/1000]  loss: 0.3902   precision: 95.00%\n",
      "[915/1000]  loss: 0.3705   precision: 94.29%\n",
      "[916/1000]  loss: 0.3322   precision: 95.71%\n",
      "[917/1000]  loss: 0.3685   precision: 94.29%\n",
      "[918/1000]  loss: 0.3021   precision: 97.14%\n",
      "[919/1000]  loss: 0.3787   precision: 95.00%\n",
      "[920/1000]  loss: 0.3357   precision: 95.71%\n",
      "[921/1000]  loss: 0.3474   precision: 95.71%\n",
      "[922/1000]  loss: 0.3217   precision: 94.29%\n",
      "[923/1000]  loss: 0.3809   precision: 93.57%\n",
      "[924/1000]  loss: 0.3331   precision: 95.71%\n",
      "[925/1000]  loss: 0.3234   precision: 97.86%\n",
      "[926/1000]  loss: 0.3404   precision: 96.43%\n",
      "[927/1000]  loss: 0.3116   precision: 95.71%\n",
      "[928/1000]  loss: 0.3333   precision: 92.86%\n",
      "[929/1000]  loss: 0.4146   precision: 93.57%\n",
      "[930/1000]  loss: 0.3527   precision: 93.57%\n",
      "[931/1000]  loss: 0.3507   precision: 93.57%\n",
      "[932/1000]  loss: 0.2936   precision: 98.57%\n",
      "[933/1000]  loss: 0.3655   precision: 92.14%\n",
      "[934/1000]  loss: 0.3810   precision: 93.57%\n",
      "[935/1000]  loss: 0.3019   precision: 95.71%\n",
      "[936/1000]  loss: 0.3275   precision: 96.43%\n",
      "[937/1000]  loss: 0.3874   precision: 93.57%\n",
      "[938/1000]  loss: 0.3932   precision: 92.14%\n",
      "[939/1000]  loss: 0.2964   precision: 95.00%\n",
      "[940/1000]  loss: 0.3769   precision: 94.29%\n",
      "[941/1000]  loss: 0.3109   precision: 97.14%\n",
      "[942/1000]  loss: 0.3152   precision: 93.57%\n",
      "[943/1000]  loss: 0.3018   precision: 95.00%\n",
      "[944/1000]  loss: 0.3317   precision: 95.00%\n",
      "[945/1000]  loss: 0.3390   precision: 96.43%\n",
      "[946/1000]  loss: 0.3101   precision: 95.00%\n",
      "[947/1000]  loss: 0.3682   precision: 93.57%\n",
      "[948/1000]  loss: 0.2849   precision: 96.43%\n",
      "[949/1000]  loss: 0.3000   precision: 95.71%\n",
      "[950/1000]  loss: 0.3789   precision: 94.29%\n",
      "[951/1000]  loss: 0.3426   precision: 95.71%\n",
      "[952/1000]  loss: 0.2957   precision: 97.86%\n",
      "[953/1000]  loss: 0.3515   precision: 94.29%\n",
      "[954/1000]  loss: 0.2813   precision: 96.43%\n",
      "[955/1000]  loss: 0.3033   precision: 94.29%\n",
      "[956/1000]  loss: 0.3605   precision: 92.86%\n",
      "[957/1000]  loss: 0.3605   precision: 97.14%\n",
      "[958/1000]  loss: 0.3003   precision: 96.43%\n",
      "[959/1000]  loss: 0.3164   precision: 95.71%\n",
      "[960/1000]  loss: 0.3152   precision: 95.00%\n",
      "[961/1000]  loss: 0.3197   precision: 93.57%\n",
      "[962/1000]  loss: 0.3046   precision: 96.43%\n",
      "[963/1000]  loss: 0.2833   precision: 95.71%\n",
      "[964/1000]  loss: 0.3332   precision: 94.29%\n",
      "[965/1000]  loss: 0.3763   precision: 92.86%\n",
      "[966/1000]  loss: 0.3495   precision: 91.43%\n",
      "[967/1000]  loss: 0.3161   precision: 96.43%\n",
      "[968/1000]  loss: 0.3959   precision: 91.43%\n",
      "[969/1000]  loss: 0.3354   precision: 95.00%\n",
      "[970/1000]  loss: 0.2593   precision: 95.00%\n",
      "[971/1000]  loss: 0.3028   precision: 95.71%\n",
      "[972/1000]  loss: 0.3354   precision: 95.00%\n",
      "[973/1000]  loss: 0.3052   precision: 94.29%\n",
      "[974/1000]  loss: 0.3875   precision: 93.57%\n",
      "[975/1000]  loss: 0.3662   precision: 97.86%\n",
      "[976/1000]  loss: 0.3397   precision: 95.71%\n",
      "[977/1000]  loss: 0.3076   precision: 93.57%\n",
      "[978/1000]  loss: 0.3290   precision: 94.29%\n",
      "[979/1000]  loss: 0.3091   precision: 92.86%\n",
      "[980/1000]  loss: 0.3395   precision: 94.29%\n",
      "[981/1000]  loss: 0.3301   precision: 95.71%\n",
      "[982/1000]  loss: 0.2975   precision: 96.43%\n",
      "[983/1000]  loss: 0.2761   precision: 95.00%\n",
      "[984/1000]  loss: 0.3220   precision: 94.29%\n",
      "[985/1000]  loss: 0.4070   precision: 93.57%\n",
      "[986/1000]  loss: 0.2966   precision: 96.43%\n",
      "[987/1000]  loss: 0.3101   precision: 97.86%\n",
      "[988/1000]  loss: 0.2765   precision: 95.71%\n",
      "[989/1000]  loss: 0.3137   precision: 95.00%\n",
      "[990/1000]  loss: 0.2384   precision: 97.14%\n",
      "[991/1000]  loss: 0.3132   precision: 92.86%\n",
      "[992/1000]  loss: 0.3075   precision: 95.00%\n",
      "[993/1000]  loss: 0.3492   precision: 95.71%\n",
      "[994/1000]  loss: 0.2658   precision: 96.43%\n",
      "[995/1000]  loss: 0.3344   precision: 95.00%\n",
      "[996/1000]  loss: 0.3335   precision: 92.86%\n",
      "[997/1000]  loss: 0.3041   precision: 97.14%\n",
      "[998/1000]  loss: 0.3317   precision: 93.57%\n",
      "[999/1000]  loss: 0.3200   precision: 95.00%\n",
      "[1000/1000]  loss: 0.2385   precision: 97.86%\n",
      "=============================================\n",
      "[Testing]  loss: 0.7080   precision: 80.30%\n",
      "=============================================\n"
     ]
    }
   ],
   "source": [
    "features = features.cuda()\n",
    "adj = adj.cuda()\n",
    "labels = labels.cuda()\n",
    "\n",
    "for i in range(NITER):\n",
    "    model.train()\n",
    "    optim.zero_grad()\n",
    "    outputs = model(features, adj)\n",
    "    predicts = outputs.argmax(dim=1)\n",
    "    loss = loss_fn(outputs[idx_train], labels[idx_train])\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    \n",
    "    precision = accuracy_score(labels[idx_train].cpu(), predicts[idx_train].cpu())\n",
    "    print(\"[{:3d}/{:3d}]  loss: {:.4f}   precision: {:5.2%}\".format(i+1, NITER, loss, precision))\n",
    "    \n",
    "    if(i % NTEST == NTEST-1):\n",
    "        model.eval()\n",
    "        outputs = model(features, adj)\n",
    "        predicts = outputs.argmax(dim=1)\n",
    "        loss = loss_fn(outputs[idx_test], labels[idx_test])\n",
    "        precision = accuracy_score(labels[idx_test].cpu(), predicts[idx_test].cpu())\n",
    "        print(\"=============================================\")\n",
    "        print(\"[Testing]  loss: {:.4f}   precision: {:5.2%}\".format(loss, precision))\n",
    "        print(\"=============================================\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
